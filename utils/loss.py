# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
"""
Loss functions
"""
import logging

import cv2
import torch
from utils.torch_utils import select_device
import torch.nn as nn
import numpy as np
import math
import torch.nn.functional as F
import argparse
from utils.metrics import bbox_iou,bbox_iou_anchor_free
from utils.torch_utils import is_parallel
from utils.general import *
from models.yolo import Model

LOGGER = logging.getLogger(__name__)
LOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))  # https://pytorch.org/docs/stable/elastic/run.html
RANK = int(os.getenv('RANK', -1))
WORLD_SIZE = int(os.getenv('WORLD_SIZE', 1))

# from general import *
def smooth_BCE(eps=0.1):  # https://github.com/ultralytics/yolov3/issues/238#issuecomment-598028441
    # return positive, negative label smoothing BCE targets
    return 1.0 - 0.5 * eps, 0.5 * eps


class BCEBlurWithLogitsLoss(nn.Module):
    # BCEwithLogitLoss() with reduced missing label effects.
    def __init__(self, alpha=0.05):
        super(BCEBlurWithLogitsLoss, self).__init__()
        self.loss_fcn = nn.BCEWithLogitsLoss(reduction='none')  # must be nn.BCEWithLogitsLoss()
        self.alpha = alpha

    def forward(self, pred, true):
        loss = self.loss_fcn(pred, true)
        pred = torch.sigmoid(pred)  # prob from logits
        dx = pred - true  # reduce only missing label effects
        # dx = (pred - true).abs()  # reduce missing label and false label effects
        alpha_factor = 1 - torch.exp((dx - 1) / (self.alpha + 1e-4))
        loss *= alpha_factor
        return loss.mean()


class FocalLoss(nn.Module):
    # Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)
    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):
        super(FocalLoss, self).__init__()
        self.loss_fcn = loss_fcn  # must be nn.BCEWithLogitsLoss()
        self.gamma = gamma
        self.alpha = alpha
        self.reduction = loss_fcn.reduction
        self.loss_fcn.reduction = 'none'  # required to apply FL to each element

    def forward(self, pred, true):
        loss = self.loss_fcn(pred, true)
        # p_t = torch.exp(-loss)
        # loss *= self.alpha * (1.000001 - p_t) ** self.gamma  # non-zero power for gradient stability

        # TF implementation https://github.com/tensorflow/addons/blob/v0.7.1/tensorflow_addons/losses/focal_loss.py
        pred_prob = torch.sigmoid(pred)  # prob from logits
        p_t = true * pred_prob + (1 - true) * (1 - pred_prob)
        alpha_factor = true * self.alpha + (1 - true) * (1 - self.alpha)
        modulating_factor = (1.0 - p_t) ** self.gamma
        loss *= alpha_factor * modulating_factor

        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else:  # 'none'
            return loss



class QFocalLoss(nn.Module):
    # Wraps Quality focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)
    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):
        super(QFocalLoss, self).__init__()
        self.loss_fcn = loss_fcn  # must be nn.BCEWithLogitsLoss()
        self.gamma = gamma
        self.alpha = alpha
        self.reduction = loss_fcn.reduction
        self.loss_fcn.reduction = 'none'  # required to apply FL to each element

    def forward(self, pred, true):
        loss = self.loss_fcn(pred, true)

        pred_prob = torch.sigmoid(pred)  # prob from logits
        alpha_factor = true * self.alpha + (1 - true) * (1 - self.alpha)
        modulating_factor = torch.abs(true - pred_prob) ** self.gamma
        loss *= alpha_factor * modulating_factor

        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else:  # 'none'
            return loss


def gaussian_label(label, num_class, u=0, sig=4.0):
    '''
    è½¬æ¢æˆCSL Labelsï¼š
        ç”¨é«˜æ–¯çª—å£å‡½æ•°æ ¹æ®è§’åº¦Î¸çš„å‘¨æœŸæ€§èµ‹äºˆgt labelsåŒæ ·çš„å‘¨æœŸæ€§ï¼Œä½¿å¾—æŸå¤±å‡½æ•°åœ¨è®¡ç®—è¾¹ç•Œå¤„æ—¶å¯ä»¥åšåˆ°â€œå·®å€¼å¾ˆå¤§ä½†losså¾ˆå°â€ï¼›
        å¹¶ä¸”ä½¿å¾—å…¶labelså…·æœ‰ç¯å½¢ç‰¹å¾ï¼Œèƒ½å¤Ÿåæ˜ å„ä¸ªÎ¸ä¹‹é—´çš„è§’åº¦è·ç¦»
    @param label: å½“å‰boxçš„Î¸ç±»åˆ«  shape(1)
    @param num_class: Î¸ç±»åˆ«æ•°é‡=180
    @param u: é«˜æ–¯å‡½æ•°ä¸­çš„Î¼
    @param sig: é«˜æ–¯å‡½æ•°ä¸­çš„Ïƒ
    @return: é«˜æ–¯ç¦»æ•£æ•°ç»„:å°†é«˜æ–¯å‡½æ•°çš„æœ€é«˜å€¼è®¾ç½®åœ¨Î¸æ‰€åœ¨çš„ä½ç½®ï¼Œä¾‹å¦‚labelä¸º45ï¼Œåˆ™å°†é«˜æ–¯åˆ†å¸ƒæ•°åˆ—å‘å³ç§»åŠ¨ç›´è‡³xè½´ä¸º45æ—¶ï¼Œå–å€¼ä¸º1 shape(180)
    '''
    # floor()è¿”å›æ•°å­—çš„ä¸‹èˆæ•´æ•°   ceil() å‡½æ•°è¿”å›æ•°å­—çš„ä¸Šå…¥æ•´æ•°  range(-90,90)
    # ä»¥num_class=180ä¸ºä¾‹ï¼Œç”Ÿæˆä»-90åˆ°89çš„æ•°å­—æ•´å½¢list  shape(180)
    x = np.array(range(math.floor(-num_class / 2), math.ceil(num_class / 2), 1))
    y_sig = np.exp(-(x - u) ** 2 / (2 * sig ** 2))  # shape(180) ä¸º-90åˆ°89çš„ç»é«˜æ–¯å…¬å¼è®¡ç®—åçš„æ•°å€¼
    # å°†é«˜æ–¯å‡½æ•°çš„æœ€é«˜å€¼è®¾ç½®åœ¨Î¸æ‰€åœ¨çš„ä½ç½®ï¼Œä¾‹å¦‚labelä¸º45ï¼Œåˆ™å°†é«˜æ–¯åˆ†å¸ƒæ•°åˆ—å‘å³ç§»åŠ¨ç›´è‡³xè½´ä¸º45æ—¶ï¼Œå–å€¼ä¸º1
    return np.concatenate([y_sig[math.ceil(num_class / 2) - int(label.item()):],
                           y_sig[:math.ceil(num_class / 2) - int(label.item())]], axis=0)



class ComputeLoss:
    # Compute losses
    def __init__(self, model, autobalance=False):
        self.sort_obj_iou = False
        device = next(model.parameters()).device  # get model device
        h = model.hyp  # hyperparameters
        self.class_index = 5 + model.nc

        # Define criteria
        BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['cls_pw']], device=device))
        BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['obj_pw']], device=device))
        BCEangle = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([h['angle_pw']])).to(device)

        # Class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3
        self.cp, self.cn = smooth_BCE(eps=h.get('label_smoothing', 0.0))  # positive, negative BCE targets

        # Focal loss
        g = h['fl_gamma']  # focal loss gamma

        if g > 0:
            BCEcls, BCEobj = FocalLoss(BCEcls, g), FocalLoss(BCEobj, g)
            BCEangle = FocalLoss(BCEangle, g)

        # è·å–æ¯ä¸€å±‚çš„output
        det = model.module.model[-1] if is_parallel(model) else model.model[-1]  # Detect() module
        self.balance = {3: [4.0, 1.0, 0.4]}.get(det.nl, [4.0, 1.0, 0.25, 0.06, .02])  # P3-P7
        self.ssi = list(det.stride).index(16) if autobalance else 0  # stride 16 index
        self.BCEcls, self.BCEobj, self.gr, self.hyp, self.autobalance = BCEcls, BCEobj, 1.0, h, autobalance
        self.BCEangle = BCEangle

        for k in 'na', 'nc', 'nl', 'anchors':
            setattr(self, k, getattr(det, k))

    def __call__(self, p, targets, imgs=None, img_path=None):  # predictions, targets, model
        '''
        @param imgs: é¢å¤–æ–°å¢çš„å‚æ•°ï¼Œå¯è§†åŒ–è®­ç»ƒæ—¶æœŸanchorå’Œtargetçš„åŒ¹é…è¿‡ç¨‹
        '''
        device = targets.device
        lcls, lbox, lobj = torch.zeros(1, device=device), torch.zeros(1, device=device), torch.zeros(1, device=device)
        langle = torch.zeros(1, device=device)

        # build_targetså‡½æ•°è¿”å›çš„ç»“æœåº”è¯¥æ˜¯æ­£æ ·æœ¬
        '''
        tcls : 3ä¸ªtensorç»„æˆçš„list (tensor_class_list[i])  å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆå¯¹åº”çš„class tensor tcls[i].shape=(num_i, 1)
            egï¼štcls[0] = tensor([73, 73, 73])
        tbox : 3ä¸ªtensorç»„æˆçš„list (box[i])  å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆå¯¹åº”çš„gt_boxä¿¡æ¯ xyï¼šå½“å‰featuremapå°ºåº¦ä¸Šçš„çœŸå®gt_xyä¸è´Ÿè´£é¢„æµ‹ç½‘æ ¼åæ ‡çš„åç§»é‡; whï¼šå½“å‰featuremapå°ºåº¦ä¸Šçš„çœŸå®gt_wh tbox[i].shape=(num_i, 4)
            eg: tbox[0] = tensor([[ 0.19355,  0.27958,  4.38709, 14.92512],
                                                 [ 1.19355,  0.27958,  4.38709, 14.92512],
                                                 [ 0.19355,  1.27958,  4.38709, 14.92512]])
        indices : ç´¢å¼•åˆ—è¡¨ ä¹Ÿç”±3ä¸ªå¤§listç»„æˆ æ¯ä¸ªlistä»£è¡¨å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆçš„ç´¢å¼•æ•°æ®ã€‚å…¶ä¸­å•ä¸ªlistä¸­çš„ç´¢å¼•æ•°æ®åˆ†åˆ«æœ‰:
            1.(è¯¥imageå±äºè¯¥batchçš„ç¬¬å‡ ä¸ªå›¾ç‰‡ ; è¯¥boxå±äºå“ªç§scaleçš„anchor; ç½‘æ ¼ç´¢å¼•1; ç½‘æ ¼ç´¢å¼•2)
            2.indices[i].shape=(4, num_i)
            egï¼š indices[0] = (tensor([0, 0, 0]), tensor([1, 1, 1]), tensor([23, 23, 22]), tensor([2, 1, 2]))
        anch : anchoråˆ—è¡¨ ä¹Ÿç”±3ä¸ªlistç»„æˆ æ¯ä¸ªlistä»£è¡¨æ¯ä¸ªæ­¥é•¿ç½‘ç»œå¯¹gtç›®æ ‡é‡‡ç”¨çš„anchorå¤§å°(å¯¹åº”featuremapå°ºåº¦ä¸Šçš„anchor_wh)
            anchor[i].shape=(num_i, 2)
            egï¼štensor([[2.00000, 3.75000],  [2.00000, 3.75000],  [2.00000, 3.75000]])
        tangle : 3ä¸ªtensorç»„æˆçš„list (tensor_angle_list[i])  å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆå¯¹åº”çš„angle tensor
            tangle[i].shape=(num_i, 1)
            egï¼štangle[0] = tensor([179, 179, 179])
        '''
        # tcls, tangle, tbox, indices, anchors = self.build_targets(p, targets)  # targets
        tcls, tangle, tbox, indices, anchors,txywh = self.build_targets(p, targets)  # å¢åŠ äº†åŒ¹é…éœ€è¦çš„txywh,add

        # add------------------------------------
        if imgs is not None:
            # vis_bbox(imgs,targets)  #å¯è§†åŒ–anchorçš„åŒ¹é…è¿‡ç¨‹ï¼Œadd
            vis_match(imgs,targets,tcls,tbox,indices,anchors,p,txywh,img_path) # å¯è§†åŒ–anchorçš„åŒ¹é…å…³ç³»ï¼Œ2021-10-18 14:31:31

        # Losses
        # pi.size= (batch_size,channel, feature_map_size1,feature_map_size2, [x,y,w,h,obj]+ num_classes +180angle)
        for i, pi in enumerate(p):  # layer index, layer predictions
            '''
            b: å½“å‰batchä¸­çš„å›¾ç‰‡ç´¢å¼•
            a: æ¯ä¸ªanchorçš„ç´¢å¼•
            gj: æ¯ä¸ªanchorçš„yåæ ‡
            gi: æ¯ä¸ªanchorçš„xåæ ‡
            '''
            b, a, gj, gi = indices[i]  # image, anchor, gridy, gridx
            tobj = torch.zeros_like(pi[..., 0], device=device)  # target obj

            n = b.shape[0]  # number of targets

            if n:
                # ps.size=(num_anchors, classes
                ps = pi[b, a, gj, gi]  # prediction subset corresponding to targets

                # Regression
                pxy = ps[:, :2].sigmoid() * 2. - 0.5
                pwh = (ps[:, 2:4].sigmoid() * 2) ** 2 * anchors[i]
                pbox = torch.cat((pxy, pwh), 1)  # predicted box

                # ä½¿ç”¨åˆ°äº†CIou loss
                iou = bbox_iou(pbox.T, tbox[i], x1y1x2y2=False, CIoU=True)  # iou(prediction, target)
                lbox += (1.0 - iou).mean()  # iou loss

                # Objectness
                score_iou = iou.detach().clamp(0).type(tobj.dtype)

                if self.sort_obj_iou:
                    sort_id = torch.argsort(score_iou)
                    b, a, gj, gi, score_iou = b[sort_id], a[sort_id], gj[sort_id], gi[sort_id], score_iou[sort_id]
                tobj[b, a, gj, gi] = (1.0 - self.gr) + self.gr * score_iou  # iou ratio

                # Classification
                if self.nc > 1:  # cls loss (only if multiple classes)
                    t = torch.full_like(ps[:, 5:self.class_index], self.cn, device=device)  # targets
                    t[range(n), tcls[i]] = self.cp # è¢«åŒ¹é…åˆ°çš„ç±»åˆ«å°±ç½®ä¸º1
                    lcls += self.BCEcls(ps[:, 5:self.class_index], t)  # BCE
                
                # Î˜ç±»åˆ«æŸå¤±
                ttheta = torch.zeros_like(ps[:, self.class_index:])  # size(num, 180)

                for idx in range(len(ps)):  # idx start from 0 to len(ps)-1
                    # 3ä¸ªtensorç»„æˆçš„list (tensor_angle_list[i])  å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆå¯¹åº”çš„class tensor  tangle[i].shape=(num_i, 1)
                    theta = tangle[i][idx]  # å–å‡ºç¬¬iä¸ªlayerä¸­çš„ç¬¬idxä¸ªç›®æ ‡çš„è§’åº¦æ•°å€¼  ä¾‹å¦‚å–å€¼Î¸=90
                    # CSLè®ºæ–‡ä¸­çª—å£åŠå¾„ä¸º6æ•ˆæœæœ€ä½³ï¼Œè¿‡å°æ— æ³•å­¦åˆ°è§’åº¦ä¿¡æ¯ï¼Œè¿‡å¤§åˆ™è§’åº¦é¢„æµ‹åå·®åŠ å¤§
                    csl_label = gaussian_label(theta, 180, u=0, sig=6)  # ç”¨é•¿åº¦ä¸º1çš„Î¸å€¼æ„å»ºé•¿åº¦ä¸º180çš„csl_label
                    ttheta[idx] = torch.from_numpy(csl_label)  # å°†cls_labelæ”¾å…¥å¯¹åº”çš„ç›®æ ‡ä¸­

                langle += self.BCEangle(ps[:, self.class_index:], ttheta)

                # Append targets to text file
                # with open('targets.txt', 'a') as file:
                #     [file.write('%11.5g ' * 4 % tuple(x) + '\n') for x in torch.cat((txy[i], twh[i]), 1)]

            obji = self.BCEobj(pi[..., 4], tobj)
            lobj += obji * self.balance[i]  # obj loss
            if self.autobalance:
                self.balance[i] = self.balance[i] * 0.9999 + 0.0001 / obji.detach().item()

        if self.autobalance:
            self.balance = [x / self.balance[self.ssi] for x in self.balance]

        lbox *= self.hyp['box']
        lobj *= self.hyp['obj']
        lcls *= self.hyp['cls']
        langle *= self.hyp['angle']
        bs = tobj.shape[0]  # batch size

        return (lbox + lobj + lcls + langle) * bs, torch.cat((lbox, lobj, lcls, langle)).detach()
    '''
        é¢„æµ‹çš„anchorä¸çœŸå®æ ‡ç­¾åšå¯¹æ¯”ï¼Œè¿›è¡Œç­›é€‰
    '''
    def build_targets(self, p, targets):
        '''
        @param p: list: [small_forward, medium_forward, large_forward]
            eg:small_forward.size=( batch_size, 1ç§scaleæ¡†, size1, size2, [class,x,y,w,h,theta])
        @param targets: size=(image_id,class,x,y,w,h,theta), image_idè¡¨ç¤ºå½“å‰targetå±äºbatchçš„å“ªä¸€å¼ 
        @param targets: torch.Size = (è¯¥batchä¸­çš„ç›®æ ‡æ•°é‡, [è¯¥imageå±äºè¯¥batchçš„ç¬¬å‡ ä¸ªå›¾ç‰‡, class, xywh, Î˜])
        @param model: æ¨¡å‹
            Returns:
                tcls : 3ä¸ªtensorç»„æˆçš„list (tensor_class_list[i])  å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆå¯¹åº”çš„class tensor
                               tcls[i].shape=(num_i, 1)
                           egï¼štcls[0] = tensor([73, 73, 73])
                tbox : 3ä¸ªtensorç»„æˆçš„list (box[i])  å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆå¯¹åº”çš„gt_boxä¿¡æ¯ xyï¼šå½“å‰featuremapå°ºåº¦ä¸Šçš„çœŸå®gt_xyä¸è´Ÿè´£é¢„æµ‹ç½‘æ ¼åæ ‡çš„åç§»é‡; whï¼šå½“å‰featuremapå°ºåº¦ä¸Šçš„çœŸå®gt_wh
                               tbox[i].shape=(num_i, 4)
                           eg: tbox[0] = tensor([[ 0.19355,  0.27958,  4.38709, 14.92512],
                                                 [ 1.19355,  0.27958,  4.38709, 14.92512],
                                                 [ 0.19355,  1.27958,  4.38709, 14.92512]])
                indices : ç´¢å¼•åˆ—è¡¨ ä¹Ÿç”±3ä¸ªå¤§listç»„æˆ æ¯ä¸ªlistä»£è¡¨å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆçš„ç´¢å¼•æ•°æ®ã€‚å…¶ä¸­å•ä¸ªlistä¸­çš„ç´¢å¼•æ•°æ®åˆ†åˆ«æœ‰:
                               (è¯¥imageå±äºè¯¥batchçš„ç¬¬å‡ ä¸ªå›¾ç‰‡ ; è¯¥boxå±äºå“ªç§scaleçš„anchor; ç½‘æ ¼ç´¢å¼•1; ç½‘æ ¼ç´¢å¼•2)
                                     indices[i].shape=(4, num_i)
                                egï¼š indices[0] = (tensor([0, 0, 0]), tensor([1, 1, 1]), tensor([23, 23, 22]), tensor([2, 1, 2]))
                anch : anchoråˆ—è¡¨ ä¹Ÿç”±3ä¸ªlistç»„æˆ æ¯ä¸ªlistä»£è¡¨æ¯ä¸ªæ­¥é•¿ç½‘ç»œå¯¹gtç›®æ ‡é‡‡ç”¨çš„anchorå¤§å°(å¯¹åº”featuremapå°ºåº¦ä¸Šçš„anchor_wh)
                                    anchor[i].shape=(num_i, 2)
                                egï¼štensor([[2.00000, 3.75000],  [2.00000, 3.75000],  [2.00000, 3.75000]])
                tangle : 3ä¸ªtensorç»„æˆçš„list (tensor_angle_list[i])  å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆå¯¹åº”çš„angle tensor
                               tangle[i].shape=(num_i, 1)
                           egï¼štangle[0] = tensor([179, 179, 179])
        '''

        na, nt = self.na, targets.shape[0]  # é¢„æµ‹æ¡†çš„ç§ç±», æ ‡ç­¾å€¼çš„æ•°é‡
        tcls, tbox, indices, anch = [], [], [], []
        tangle = []
        txywh = [] # add, ä¸ºå¯è§†åŒ–æä¾›xy,wh

        gain = torch.ones(8, device=targets.device)  # normalized to grid space gain

        '''
        naæ˜¯anchorçš„æ•°é‡ï¼Œå‡å¦‚na=3ï¼Œé‚£ä¹ˆtorch.arange(na) = tensor[0,1,2];
        ç„¶åè½¬åŒ–æˆfloatå‹æ•°æ®ï¼Œæœ€åç»´åº¦å±•å¼€ä¸º(3,1)=tensor[[0.],[1.],[2.]];
        repeat(1,nt),æ²¿ç€ä¸Šé¢çš„ç¬¬äºŒä¸ªç»´åº¦è¿›è¡Œå¤åˆ¶ntæ¬¡ï¼Œnt=çœŸå®æ ‡ç­¾çš„æ•°é‡;
        æ‰€ä»¥aiè¡¨ç¤ºanchorçš„ç´¢å¼•ai = anchor_index = (naï¼Œnt).
        '''
        ai = torch.arange(na, device=targets.device).float().view(na, 1).repeat(1, nt)

        '''
        1.ai[:, :, None]:è¿™é‡Œå°†åŸæœ¬2ä¸ªç»´åº¦çš„aiå¢åŠ äº†ä¸€ä¸ªç»´åº¦=(na,nt,1);
        2.targets.repeat(na, 1, 1): targetä¸€å…±ä¸¤ä¸ªç»´åº¦(number_of_targetsï¼Œ[image,class,x,y,w,h])è¿›è¡Œç»´åº¦æ‰©å±•ï¼Œå‡å¦‚na=3ï¼Œé‚£ä¹ˆæ‰©å±•åçš„ç»´åº¦
            targets.repeat(na, 1, 1)=(na, nt, [image,class,x,y,w,h])
        3.å†å°†ä¸¤ä¸ªä¸‰ç»´çŸ©é˜µåœ¨ç¬¬2ä¸ªç»´åº¦è¿›è¡Œè¿›è¡Œæ‹¼æ¥ï¼Œå³(na, nt, 1+6)
        eg: ç›®çš„æ˜¯ä¸ºäº†å°†é¢„æµ‹æ¡†å’Œæ ‡ç­¾å€¼è¿›è¡ŒçŸ©é˜µæ‹¼æ¥ï¼Œæ¥ä¸‹æ¥è¿›è¡Œç­›é€‰ç­–ç•¥ã€‚
        4.targetsæ­¤æ—¶çš„size = (num_anchor, num_gt, [img_id, cls_id, x,y,w,h,theta, anchor_index])
        '''
        targets = torch.cat((targets.repeat(na, 1, 1), ai[:, :, None]), 2)  # append anchor indices


        '''
        offåç½®çŸ©é˜µï¼Œè·å–ä¸Šä¸‹å·¦å³å››ä¸ªç‚¹åŠå½“å‰çš„ç‚¹
            tensor([[ 0.00000,  0.00000],
            [ 0.50000,  0.00000],
            [ 0.00000,  0.50000],
            [-0.50000,  0.00000],
            [ 0.00000, -0.50000]])
        '''
        g = 0.5  # bias
        off = torch.tensor([[0, 0],[1, 0], [0, 1], [-1, 0], [0, -1],  # j,k,l,m
                            # [1, 1], [1, -1], [-1, 1], [-1, -1],  # jk,jm,lk,lm
                            ], device=targets.device).float() * g  # offsets

        # å¯¹ä¸‰ä¸ªç‰¹å¾å±‚ä¾æ¬¡å¤„ç†ï¼Œanchorä¹Ÿè¿›è¡ŒåŒæ¯”ä¾‹ç¼©æ”¾ï¼Œ8,16,32
        for i in range(self.nl):
            # è·å–å½“å‰ç‰¹å¾å±‚çš„é¢„è®¾çš„anchorï¼Œanchor basedç‰ˆæœ¬æœ‰ä¸‰ç§é¢„è®¾å€¼ï¼Œæ‰€ä»¥anchorsæ˜¯ä¸€ä¸ªlist
            # anchors size=ï¼ˆ3ä¸­scale, 2(w,h)ï¼‰
            anchors = self.anchors[i]

            # gain[2:6]å…¨æ˜¯80ï¼Œ
            # torch.tensor(p[i].shape)[[3, 2, 3, 2]]è·å–p[i]å±‚çš„å¯¹åº”ç´¢å¼•ä½çš„ç»´åº¦æ•°ï¼Œç¬¬3ä¸ªç»´åº¦ï¼Œç¬¬2ä¸ªç»´åº¦Â·Â·Â·
            gain[2:6] = torch.tensor(p[i].shape)[[3, 2, 3, 2]]  # xyxy gain

            # Match targets to anchors
            # targetså·²ç»è¢«å½’ä¸€åŒ–å¤„ç†ï¼Œç„¶åé€šè¿‡gainçŸ©é˜µä¸­è·å–çš„ç‰¹å¾å›¾å¤§å°è¿›è¡Œæ˜ å°„ï¼ŒæŠ•å½±åˆ°ç‰¹å¾å›¾ä¸Šå»
            t = targets * gain

            if nt:  # æ ‡ç­¾æ•°é‡
                # åŒ¹é…ç­–ç•¥
                '''
                # t[:, :, 4:6]: ç´¢å¼•æ ‡ç­¾å€¼çš„ç¬¬4ï¼Œ5ç»´æ•°æ®ï¼Œå³w,hï¼›
                # anchors[:, None]: æ‰©å¼ ç¬¬äºŒä¸ªç»´åº¦ï¼Œï¼ˆ3,2ï¼‰->(3,1,2)
                # r: è·å¾—å®½é«˜æ¯”
                '''
                r = t[:, :, 4:6] / anchors[:, None]  # wh ratio

                # å¦‚æœæ¯ä¸ªæ ‡ç­¾å€¼å’Œanchorçš„whæ¯”æœ€å¤§å€¼å°äºè¶…å‚æ•°é‡Œé¢çš„é¢„è®¾å€¼ï¼Œåˆ™è¯¥anchorä¸ºåˆé€‚çš„anchor
                j = torch.max(r, 1. / r).max(2)[0] < self.hyp['anchor_t']
                # j = wh_iou(anchors, t[:, 4:6]) > model.hyp['iou_t']  # iou(3,n)=wh_iou(anchors(3,2), gwh(n,2))
                t = t[j]  # è¿›è¡Œè¿‡æ»¤

                # Offsets
                # ä»¥å›¾åƒå·¦ä¸Šè§’ä¸ºåŸç‚¹ï¼Œgxyä¸ºæ ‡ç­¾å€¼çš„x,yåæ ‡
                # ç„¶åè½¬åŒ–ä¸ºä»¥ç‰¹å¾å›¾å³ä¸‹è§’ä¸ºåŸç‚¹ï¼Œå³target[x,y] -> (80-x, 80-y)
                gxy = t[:, 2:4]  # grid xy
                gxi = gain[[2, 3]] - gxy  # inverse

                # gxiï¼šè½¬æ¢åçš„æ ‡ç­¾çš„xyåæ ‡ï¼ˆå³ä¸‹è§’ä¸ºåŸç‚¹ï¼‰ï¼Œgxy: çœŸå®æ ‡ç­¾çš„xyå·¦è¾¹ï¼ˆå·¦ä¸Šè§’ä¸ºåŸç‚¹ï¼‰
                # j,lçŸ©é˜µäº’æ–¥ï¼Œk,mçŸ©é˜µäº’æ–¥
                j, k = ((gxy % 1. < g) & (gxy > 1.)).T # åˆ¤æ–­è½¬æ¢å‰çš„xï¼Œyæ˜¯å¦å¤§äº1ï¼Œå¹¶ä¸”xè·å®ƒå·¦è¾¹,yè·å®ƒä¸Šè¾¹çš„ç½‘æ ¼è·ç¦»æ˜¯å¦<0.5?å¦‚æœéƒ½æ»¡è¶³æ¡ä»¶ï¼Œåˆ™é€‰ä¸­
                l, m = ((gxi % 1. < g) & (gxi > 1.)).T # åŒç†å¯¹è½¬æ¢åçš„åæ ‡åˆ¤æ–­xè·å®ƒç½‘æ ¼çš„å³è¾¹ï¼Œyè·å®ƒç½‘æ ¼ä¸‹è¾¹æ˜¯å¦åŒæ—¶æ»¡è¶³ä¸Šè¿°ä¸¤ä¸ªæ¡ä»¶ã€‚

                # ç„¶åjæ˜¯ä¸€ä¸ªboolå˜é‡çš„çŸ©é˜µï¼Œsize=ï¼ˆ5ï¼Œæ ‡ç­¾çš„æ•°é‡ï¼‰,å‡è®¾(5,15)
                # ç„¶åå°†è¿™å‡ ä¸ªçŸ©é˜µè¿›è¡Œè¿æ¥èµ·æ¥
                j = torch.stack((torch.ones_like(j), j, k, l, m))

                # t.repeat((5, 1, 1))ï¼šåœ¨ï¼ˆ15,8ï¼‰ç¬¬0ç»´å‰é‡å¤5æ¬¡->(5,15,8)
                # è¿™é‡Œå¯¹æ­£æ ·æœ¬è¿›è¡Œäº†æ‰©å……
                t = t.repeat((5, 1, 1))[j] # è¿‡æ»¤åï¼Œtå‰©ä¸‹ä¸¤ä¸ªç»´åº¦ï¼Œ[select_anchors, 8], å³ç­›é€‰å‡ºæ¥çš„anchor

                # è·å–æ‰€æœ‰æ ‡ç­¾å€¼çš„åç½®
                offsets = (torch.zeros_like(gxy)[None] + off[:, None])[j]
            else:
                t = targets[0]
                offsets = 0

            # Define
            b, c = t[:, :2].long().T  # è·å–æ¯ä¸ªæ ‡ç­¾çš„å›¾åƒï¼Œç±»åˆ«ç´¢å¼•ï¼Œç¬¬0,1ç»´åº¦
            angle = t[:, 6].long()  # è·å–è§’åº¦ç´¢å¼•ï¼Œç¬¬6ä¸ªç»´åº¦
            gxy = t[:, 2:4]  # grid xy
            gwh = t[:, 4:6]  # grid wh
            gij = (gxy - offsets).long() # è·å–è¢«åŒ¹é…çš„anchorçš„x,yåæ ‡
            gi, gj = gij.T  # grid xy indices

            # Append
            a = t[:, 7].long()  # æ¯ä¸ªanchorçš„ç´¢å¼•
            indices.append((b, a, gj.clamp_(0, gain[3] - 1), gi.clamp_(0, gain[2] - 1)))  # ä¿å­˜å›¾ç‰‡åºå·ã€anchorç´¢å¼•ã€ç½‘æ ¼ç‚¹åæ ‡
            tbox.append(torch.cat((gxy - gij, gwh), 1))  # è·å–xyç›¸å¯¹äºç½‘æ ¼ç‚¹çš„åç½®ï¼Œä»¥åŠboxå®½é«˜
            anch.append(anchors[a])  # anchors
            tcls.append(c)  # class
            tangle.append(angle)  # angle
            txywh.append(torch.cat((gxy,gwh),1)) # å¯è§†åŒ–å¢åŠ xy,wh
        return tcls, tangle, tbox, indices, anch , txywh


class ComputeLoss_AnchorFree:
    # Compute losses
    def __init__(self, model, autobalance=False):
        self.sort_obj_iou = False
        device = next(model.parameters()).device  # get model device
        h = model.hyp  # hyperparameters
        self.class_index = 5 + model.nc

        # Define criteria
        BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['cls_pw']], device=device))
        BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['obj_pw']], device=device))
        BCEangle = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([h['angle_pw']])).to(device)

        # Class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3
        self.cp, self.cn = smooth_BCE(eps=h.get('label_smoothing', 0.0))  # positive, negative BCE targets

        # Focal loss
        g = h['fl_gamma']  # focal loss gamma
        if g > 0:
            BCEcls, BCEobj = FocalLoss(BCEcls, g), FocalLoss(BCEobj, g)
            BCEangle = FocalLoss(BCEangle, g)

        # è·å–æ¯ä¸€å±‚çš„output
        det = model.module.model[-1] if is_parallel(model) else model.model[-1]  # Detect() module
        self.balance = {3: [4.0, 1.0, 0.4]}.get(det.nl, [4.0, 1.0, 0.25, 0.06, .02])  # P3-P7
        self.ssi = list(det.stride).index(16) if autobalance else 0  # stride 16 index
        self.BCEcls, self.BCEobj, self.gr, self.hyp, self.autobalance = BCEcls, BCEobj, 1.0, h, autobalance
        self.BCEangle = BCEangle

        for k in 'na', 'nc', 'nl', 'anchors':
            setattr(self, k, getattr(det, k))

    def __call__(self, p, targets):  # predictions, targets, model
        device = targets.device
        lcls, lbox, lobj = torch.zeros(1, device=device), torch.zeros(1, device=device), torch.zeros(1, device=device)
        langle = torch.zeros(1, device=device)

        # build_targetså‡½æ•°è¿”å›çš„ç»“æœåº”è¯¥æ˜¯æ­£æ ·æœ¬
        '''
        tcls : 3ä¸ªtensorç»„æˆçš„list (tensor_class_list[i])  å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆå¯¹åº”çš„class tensor tcls[i].shape=(num_i, 1)
            egï¼štcls[0] = tensor([73, 73, 73])
        tbox : 3ä¸ªtensorç»„æˆçš„list (box[i])  å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆå¯¹åº”çš„gt_boxä¿¡æ¯ xyï¼šå½“å‰featuremapå°ºåº¦ä¸Šçš„çœŸå®gt_xyä¸è´Ÿè´£é¢„æµ‹ç½‘æ ¼åæ ‡çš„åç§»é‡; whï¼šå½“å‰featuremapå°ºåº¦ä¸Šçš„çœŸå®gt_wh tbox[i].shape=(num_i, 4)
            eg: tbox[0] = tensor([[ 0.19355,  0.27958,  4.38709, 14.92512],
                                                 [ 1.19355,  0.27958,  4.38709, 14.92512],
                                                 [ 0.19355,  1.27958,  4.38709, 14.92512]])
        indices : ç´¢å¼•åˆ—è¡¨ ä¹Ÿç”±3ä¸ªå¤§listç»„æˆ æ¯ä¸ªlistä»£è¡¨å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆçš„ç´¢å¼•æ•°æ®ã€‚å…¶ä¸­å•ä¸ªlistä¸­çš„ç´¢å¼•æ•°æ®åˆ†åˆ«æœ‰:
            1.(è¯¥imageå±äºè¯¥batchçš„ç¬¬å‡ ä¸ªå›¾ç‰‡ ; è¯¥boxå±äºå“ªç§scaleçš„anchor; ç½‘æ ¼ç´¢å¼•1; ç½‘æ ¼ç´¢å¼•2)
            2.indices[i].shape=(4, num_i)
            egï¼š indices[0] = (tensor([0, 0, 0]), tensor([1, 1, 1]), tensor([23, 23, 22]), tensor([2, 1, 2]))
        anch : anchoråˆ—è¡¨ ä¹Ÿç”±3ä¸ªlistç»„æˆ æ¯ä¸ªlistä»£è¡¨æ¯ä¸ªæ­¥é•¿ç½‘ç»œå¯¹gtç›®æ ‡é‡‡ç”¨çš„anchorå¤§å°(å¯¹åº”featuremapå°ºåº¦ä¸Šçš„anchor_wh)
            anchor[i].shape=(num_i, 2)
            egï¼štensor([[2.00000, 3.75000],  [2.00000, 3.75000],  [2.00000, 3.75000]])
        tangle : 3ä¸ªtensorç»„æˆçš„list (tensor_angle_list[i])  å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆå¯¹åº”çš„angle tensor
            tangle[i].shape=(num_i, 1)
            egï¼štangle[0] = tensor([179, 179, 179])
        '''
        tcls, tangle, tbox, indices, anchors = self.build_targets(p, targets)  # targets

        # å¯è§†åŒ–targetï¼Œ2021-10-18 14:28:36
        # vis_bbox(p,targets)

        # å¯è§†åŒ–anchorçš„åŒ¹é…å…³ç³»ï¼Œ2021-10-18 14:31:31
        # vis_match(p,targets,tcls,tbox,indices,anchors)

        # Losses
        # pi.size= (batch_size,channel, feature_map_size1,feature_map_size2, [x,y,w,h,obj]+ num_classes +180angle)
        for i, pi in enumerate(p):  # layer index, layer predictions
            '''
            b: å½“å‰batchä¸­çš„å›¾ç‰‡ç´¢å¼•
            a: æ¯ä¸ªanchorçš„ç´¢å¼•
            gj: æ¯ä¸ªanchorçš„yåæ ‡
            gi: æ¯ä¸ªanchorçš„xåæ ‡
            '''
            b, a, gj, gi = indices[i]  # image, anchor, gridy, gridx
            tobj = torch.zeros_like(pi[..., 0], device=device)  # target obj

            n = b.shape[0]  # number of targets
            if n:
                # ps.size=(num_anchors, classes
                ps = pi[b, a, gj, gi]  # prediction subset corresponding to targets

                # Regression
                pxy = ps[:, :2].sigmoid() * 2. - 0.5
                pwh = (ps[:, 2:4].sigmoid() * 2) ** 2 * anchors[i]
                pbox = torch.cat((pxy, pwh), 1)  # predicted box

                # ä½¿ç”¨åˆ°äº†CIou loss
                iou = bbox_iou(pbox.T, tbox[i], x1y1x2y2=False, CIoU=True)  # iou(prediction, target)
                lbox += (1.0 - iou).mean()  # iou loss

                # Objectness
                score_iou = iou.detach().clamp(0).type(tobj.dtype)

                if self.sort_obj_iou:
                    sort_id = torch.argsort(score_iou)
                    b, a, gj, gi, score_iou = b[sort_id], a[sort_id], gj[sort_id], gi[sort_id], score_iou[sort_id]
                tobj[b, a, gj, gi] = (1.0 - self.gr) + self.gr * score_iou  # iou ratio

                # Classification
                if self.nc > 1:  # cls loss (only if multiple classes)
                    t = torch.full_like(ps[:, 5:self.class_index], self.cn, device=device)  # targets
                    t[range(n), tcls[i]] = self.cp
                    lcls += self.BCEcls(ps[:, 5:self.class_index], t)  # BCE

                # Î˜ç±»åˆ«æŸå¤±
                ttheta = torch.zeros_like(ps[:, self.class_index:])  # size(num, 180)

                for idx in range(len(ps)):  # idx start from 0 to len(ps)-1
                    # 3ä¸ªtensorç»„æˆçš„list (tensor_angle_list[i])  å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆå¯¹åº”çš„class tensor  tangle[i].shape=(num_i, 1)
                    theta = tangle[i][idx]  # å–å‡ºç¬¬iä¸ªlayerä¸­çš„ç¬¬idxä¸ªç›®æ ‡çš„è§’åº¦æ•°å€¼  ä¾‹å¦‚å–å€¼Î¸=90
                    # CSLè®ºæ–‡ä¸­çª—å£åŠå¾„ä¸º6æ•ˆæœæœ€ä½³ï¼Œè¿‡å°æ— æ³•å­¦åˆ°è§’åº¦ä¿¡æ¯ï¼Œè¿‡å¤§åˆ™è§’åº¦é¢„æµ‹åå·®åŠ å¤§
                    csl_label = gaussian_label(theta, 180, u=0, sig=6)  # ç”¨é•¿åº¦ä¸º1çš„Î¸å€¼æ„å»ºé•¿åº¦ä¸º180çš„csl_label
                    ttheta[idx] = torch.from_numpy(csl_label)  # å°†cls_labelæ”¾å…¥å¯¹åº”çš„ç›®æ ‡ä¸­

                langle += self.BCEangle(ps[:, self.class_index:], ttheta)

                # Append targets to text file
                # with open('targets.txt', 'a') as file:
                #     [file.write('%11.5g ' * 4 % tuple(x) + '\n') for x in torch.cat((txy[i], twh[i]), 1)]

            obji = self.BCEobj(pi[..., 4], tobj)
            lobj += obji * self.balance[i]  # obj loss
            if self.autobalance:
                self.balance[i] = self.balance[i] * 0.9999 + 0.0001 / obji.detach().item()

        if self.autobalance:
            self.balance = [x / self.balance[self.ssi] for x in self.balance]

        lbox *= self.hyp['box']
        lobj *= self.hyp['obj']
        lcls *= self.hyp['cls']
        langle *= self.hyp['angle']
        bs = tobj.shape[0]  # batch size

        return (lbox + lobj + lcls + langle) * bs, torch.cat((lbox, lobj, lcls, langle)).detach()

    '''
        é¢„æµ‹çš„anchorä¸çœŸå®æ ‡ç­¾åšå¯¹æ¯”ï¼Œè¿›è¡Œç­›é€‰
    '''

    def build_targets(self, p, targets):
        '''
        @param p: list: [small_forward, medium_forward, large_forward]
            eg:small_forward.size=( batch_size, 1ç§scaleæ¡†, size1, size2, [class,x,y,w,h,theta])
        @param targets: size=(image,class,x,y,w,h,theta)
        @param targets: torch.Size = (è¯¥batchä¸­çš„ç›®æ ‡æ•°é‡, [è¯¥imageå±äºè¯¥batchçš„ç¬¬å‡ ä¸ªå›¾ç‰‡, class, xywh, Î˜])
        @param model: æ¨¡å‹
            Returns:
                tcls : 3ä¸ªtensorç»„æˆçš„list (tensor_class_list[i])  å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆå¯¹åº”çš„class tensor
                               tcls[i].shape=(num_i, 1)
                           egï¼štcls[0] = tensor([73, 73, 73])
                tbox : 3ä¸ªtensorç»„æˆçš„list (box[i])  å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆå¯¹åº”çš„gt_boxä¿¡æ¯ xyï¼šå½“å‰featuremapå°ºåº¦ä¸Šçš„çœŸå®gt_xyä¸è´Ÿè´£é¢„æµ‹ç½‘æ ¼åæ ‡çš„åç§»é‡; whï¼šå½“å‰featuremapå°ºåº¦ä¸Šçš„çœŸå®gt_wh
                               tbox[i].shape=(num_i, 4)
                           eg: tbox[0] = tensor([[ 0.19355,  0.27958,  4.38709, 14.92512],
                                                 [ 1.19355,  0.27958,  4.38709, 14.92512],
                                                 [ 0.19355,  1.27958,  4.38709, 14.92512]])
                indices : ç´¢å¼•åˆ—è¡¨ ä¹Ÿç”±3ä¸ªå¤§listç»„æˆ æ¯ä¸ªlistä»£è¡¨å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆçš„ç´¢å¼•æ•°æ®ã€‚å…¶ä¸­å•ä¸ªlistä¸­çš„ç´¢å¼•æ•°æ®åˆ†åˆ«æœ‰:
                               (è¯¥imageå±äºè¯¥batchçš„ç¬¬å‡ ä¸ªå›¾ç‰‡ ; è¯¥boxå±äºå“ªç§scaleçš„anchor; ç½‘æ ¼ç´¢å¼•1; ç½‘æ ¼ç´¢å¼•2)
                                     indices[i].shape=(4, num_i)
                                egï¼š indices[0] = (tensor([0, 0, 0]), tensor([1, 1, 1]), tensor([23, 23, 22]), tensor([2, 1, 2]))
                anch : anchoråˆ—è¡¨ ä¹Ÿç”±3ä¸ªlistç»„æˆ æ¯ä¸ªlistä»£è¡¨æ¯ä¸ªæ­¥é•¿ç½‘ç»œå¯¹gtç›®æ ‡é‡‡ç”¨çš„anchorå¤§å°(å¯¹åº”featuremapå°ºåº¦ä¸Šçš„anchor_wh)
                                    anchor[i].shape=(num_i, 2)
                                egï¼štensor([[2.00000, 3.75000],  [2.00000, 3.75000],  [2.00000, 3.75000]])
                tangle : 3ä¸ªtensorç»„æˆçš„list (tensor_angle_list[i])  å¯¹æ¯ä¸ªæ­¥é•¿ç½‘ç»œç”Ÿæˆå¯¹åº”çš„angle tensor
                               tangle[i].shape=(num_i, 1)
                           egï¼štangle[0] = tensor([179, 179, 179])
        '''

        na, nt = self.na, targets.shape[0]  # é¢„æµ‹æ¡†çš„ç§ç±», æ ‡ç­¾å€¼çš„æ•°é‡
        tcls, tbox, indices, anch = [], [], [], []
        tangle = []
        gain = torch.ones(8, device=targets.device)  # normalized to grid space gain

        '''
        naæ˜¯anchorçš„æ•°é‡ï¼Œå‡å¦‚na=3ï¼Œé‚£ä¹ˆtorch.arange(na) = tensor[0,1,2];
        ç„¶åè½¬åŒ–æˆfloatå‹æ•°æ®ï¼Œæœ€åç»´åº¦å±•å¼€ä¸º(3,1)=tensor[[0.],[1.],[2.]];
        repeat(1,nt),æ²¿ç€ä¸Šé¢çš„ç¬¬äºŒä¸ªç»´åº¦è¿›è¡Œå¤åˆ¶ntæ¬¡ï¼Œnt=çœŸå®æ ‡ç­¾çš„æ•°é‡;
        æ‰€ä»¥aiè¡¨ç¤ºanchorçš„ç´¢å¼•ai = anchor_index = (naï¼Œnt).
        '''
        ai = torch.arange(na, device=targets.device).float().view(na, 1).repeat(1, nt)

        '''
        1.ai[:, :, None]:è¿™é‡Œå°†åŸæœ¬2ä¸ªç»´åº¦çš„aiå¢åŠ äº†ä¸€ä¸ªç»´åº¦=(na,nt,1);
        2.targets.repeat(na, 1, 1): targetä¸€å…±ä¸¤ä¸ªç»´åº¦(number_of_targetsï¼Œ[image,class,x,y,w,h])è¿›è¡Œç»´åº¦æ‰©å±•ï¼Œå‡å¦‚na=3ï¼Œé‚£ä¹ˆæ‰©å±•åçš„ç»´åº¦
            targets.repeat(na, 1, 1)=(na, nt, [image,class,x,y,w,h])
        3.å†å°†ä¸¤ä¸ªä¸‰ç»´çŸ©é˜µåœ¨ç¬¬2ä¸ªç»´åº¦è¿›è¡Œè¿›è¡Œæ‹¼æ¥ï¼Œå³(na, nt, 1+6)
        eg: ç›®çš„æ˜¯ä¸ºäº†å°†é¢„æµ‹æ¡†å’Œæ ‡ç­¾å€¼è¿›è¡ŒçŸ©é˜µæ‹¼æ¥ï¼Œæ¥ä¸‹æ¥è¿›è¡Œç­›é€‰ç­–ç•¥ã€‚
        4.targetsæ­¤æ—¶çš„size = (num_anchor, num_gt, [img_id, cls_id, x,y,w,h,theta, anchor_index])
        '''
        targets = torch.cat((targets.repeat(na, 1, 1), ai[:, :, None]), 2)  # append anchor indices

        '''
        offåç½®çŸ©é˜µï¼Œè·å–ä¸Šä¸‹å·¦å³å››ä¸ªç‚¹åŠå½“å‰çš„ç‚¹
            tensor([[ 0.00000,  0.00000],
            [ 0.50000,  0.00000],
            [ 0.00000,  0.50000],
            [-0.50000,  0.00000],
            [ 0.00000, -0.50000]])
        '''
        g = 0.5  # bias
        off = torch.tensor([[0, 0], [1, 0], [0, 1], [-1, 0], [0, -1],  # j,k,l,m
                            # [1, 1], [1, -1], [-1, 1], [-1, -1],  # jk,jm,lk,lm
                            ], device=targets.device).float() * g  # offsets

        # å¯¹ä¸‰ä¸ªç‰¹å¾å±‚ä¾æ¬¡å¤„ç†ï¼Œanchorä¹Ÿè¿›è¡ŒåŒæ¯”ä¾‹ç¼©æ”¾ï¼Œ8,16,32
        for i in range(self.nl):
            # è·å–å½“å‰ç‰¹å¾å±‚çš„é¢„è®¾çš„anchorï¼Œanchor basedç‰ˆæœ¬æœ‰ä¸‰ç§é¢„è®¾å€¼ï¼Œæ‰€ä»¥anchorsæ˜¯ä¸€ä¸ªlist
            # anchors size=ï¼ˆ3ä¸­scale, 2(w,h)ï¼‰
            anchors = self.anchors[i]

            # gain[2:6]å…¨æ˜¯80ï¼Œ
            # torch.tensor(p[i].shape)[[3, 2, 3, 2]]è·å–p[i]å±‚çš„å¯¹åº”ç´¢å¼•ä½çš„ç»´åº¦æ•°ï¼Œç¬¬3ä¸ªç»´åº¦ï¼Œç¬¬2ä¸ªç»´åº¦Â·Â·Â·
            gain[2:6] = torch.tensor(p[i].shape)[[3, 2, 3, 2]]  # xyxy gain

            # Match targets to anchors
            # targetså·²ç»è¢«å½’ä¸€åŒ–å¤„ç†ï¼Œç„¶åé€šè¿‡gainçŸ©é˜µä¸­è·å–çš„ç‰¹å¾å›¾å¤§å°è¿›è¡Œæ˜ å°„ï¼ŒæŠ•å½±åˆ°ç‰¹å¾å›¾ä¸Šå»
            t = targets * gain

            if nt:  # æ ‡ç­¾æ•°é‡
                # åŒ¹é…ç­–ç•¥
                '''
                # t[:, :, 4:6]: ç´¢å¼•æ ‡ç­¾å€¼çš„ç¬¬4ï¼Œ5ç»´æ•°æ®ï¼Œå³w,hï¼›
                # anchors[:, None]: æ‰©å¼ ç¬¬äºŒä¸ªç»´åº¦ï¼Œï¼ˆ3,2ï¼‰->(3,1,2)
                # r: è·å¾—å®½é«˜æ¯”
                '''
                r = t[:, :, 4:6] / anchors[:, None]  # wh ratio

                # å¦‚æœæ¯ä¸ªæ ‡ç­¾å€¼å’Œanchorçš„whæ¯”æœ€å¤§å€¼å°äºè¶…å‚æ•°é‡Œé¢çš„é¢„è®¾å€¼ï¼Œåˆ™è¯¥anchorä¸ºåˆé€‚çš„anchor
                j = torch.max(r, 1. / r).max(2)[0] < self.hyp['anchor_t']
                # j = wh_iou(anchors, t[:, 4:6]) > model.hyp['iou_t']  # iou(3,n)=wh_iou(anchors(3,2), gwh(n,2))
                t = t[j]  # è¿›è¡Œè¿‡æ»¤

                # Offsets
                # ä»¥å›¾åƒå·¦ä¸Šè§’ä¸ºåŸç‚¹ï¼Œgxyä¸ºæ ‡ç­¾å€¼çš„x,yåæ ‡
                # ç„¶åè½¬åŒ–ä¸ºä»¥ç‰¹å¾å›¾å³ä¸‹è§’ä¸ºåŸç‚¹ï¼Œå³target[x,y] -> (80-x, 80-y)
                gxy = t[:, 2:4]  # grid xy
                gxi = gain[[2, 3]] - gxy  # inverse

                # gxiï¼šè½¬æ¢åçš„æ ‡ç­¾çš„xyåæ ‡ï¼ˆå³ä¸‹è§’ä¸ºåŸç‚¹ï¼‰ï¼Œgxy: çœŸå®æ ‡ç­¾çš„xyå·¦è¾¹ï¼ˆå·¦ä¸Šè§’ä¸ºåŸç‚¹ï¼‰
                # j,lçŸ©é˜µäº’æ–¥ï¼Œk,mçŸ©é˜µäº’æ–¥
                j, k = ((gxy % 1. < g) & (gxy > 1.)).T  # åˆ¤æ–­è½¬æ¢å‰çš„xï¼Œyæ˜¯å¦å¤§äº1ï¼Œå¹¶ä¸”xè·å®ƒå·¦è¾¹,yè·å®ƒä¸Šè¾¹çš„ç½‘æ ¼è·ç¦»æ˜¯å¦<0.5?å¦‚æœéƒ½æ»¡è¶³æ¡ä»¶ï¼Œåˆ™é€‰ä¸­
                l, m = ((gxi % 1. < g) & (gxi > 1.)).T  # åŒç†å¯¹è½¬æ¢åçš„åæ ‡åˆ¤æ–­xè·å®ƒç½‘æ ¼çš„å³è¾¹ï¼Œyè·å®ƒç½‘æ ¼ä¸‹è¾¹æ˜¯å¦åŒæ—¶æ»¡è¶³ä¸Šè¿°ä¸¤ä¸ªæ¡ä»¶ã€‚

                # ç„¶åjæ˜¯ä¸€ä¸ªboolå˜é‡çš„çŸ©é˜µï¼Œsize=ï¼ˆ5ï¼Œæ ‡ç­¾çš„æ•°é‡ï¼‰,å‡è®¾(5,15)
                # ç„¶åå°†è¿™å‡ ä¸ªçŸ©é˜µè¿›è¡Œè¿æ¥èµ·æ¥
                j = torch.stack((torch.ones_like(j), j, k, l, m))

                # t.repeat((5, 1, 1))ï¼šåœ¨ï¼ˆ15,8ï¼‰ç¬¬0ç»´å‰é‡å¤5æ¬¡->(5,15,8)
                # è¿™é‡Œè·å–å·²ç»åŒ¹é…åˆ°äº†çš„anchor
                t = t.repeat((5, 1, 1))[j]  # è¿‡æ»¤åï¼Œtå‰©ä¸‹ä¸¤ä¸ªç»´åº¦ï¼Œ[select_anchors, 8], å³ç­›é€‰å‡ºæ¥çš„anchor

                # è·å–æ‰€æœ‰æ ‡ç­¾å€¼çš„åç½®
                offsets = (torch.zeros_like(gxy)[None] + off[:, None])[j]
            else:
                t = targets[0]
                offsets = 0

            # Define
            b, c = t[:, :2].long().T  # è·å–æ¯ä¸ªæ ‡ç­¾çš„å›¾åƒï¼Œç±»åˆ«ç´¢å¼•ï¼Œç¬¬0,1ç»´åº¦
            angle = t[:, 6].long()  # è·å–è§’åº¦ç´¢å¼•ï¼Œç¬¬6ä¸ªç»´åº¦
            gxy = t[:, 2:4]  # grid xy
            gwh = t[:, 4:6]  # grid wh
            gij = (gxy - offsets).long()  # è·å–æ¯ä¸ªboxæ‰€åœ¨ç½‘æ ¼ç‚¹çš„åæ ‡
            gi, gj = gij.T  # grid xy indices

            # Append
            a = t[:, 7].long()  # æ¯ä¸ªanchorçš„ç´¢å¼•
            indices.append((b, a, gj.clamp_(0, gain[3] - 1), gi.clamp_(0, gain[2] - 1)))  # ä¿å­˜å›¾ç‰‡åºå·ã€anchorç´¢å¼•ã€ç½‘æ ¼ç‚¹åæ ‡
            tbox.append(torch.cat((gxy - gij, gwh), 1))  # è·å–xyç›¸å¯¹äºç½‘æ ¼ç‚¹çš„åç½®ï¼Œä»¥åŠboxå®½é«˜
            anch.append(anchors[a])  # anchors
            tcls.append(c)  # class
            tangle.append(angle)  # angle

        return tcls, tangle, tbox, indices, anch

'''
2021å¹´11æœˆ10æ—¥14:16:50
åŠŸèƒ½ï¼šè§£è€¦åˆåçš„æŸå¤±å‡½æ•°
'''

class KLDloss(nn.Module):
    def __init__(self, taf=1.0, reduction="none"):
        super(KLDloss, self).__init__()
        self.reduction = reduction
        self.taf = taf

    def forward(self, pred, target):
        # pred [[x,y,w,h,angle], ...]
        assert pred.shape[0] == target.shape[0]

        pred = pred.view(-1, 5)
        target = target.view(-1, 5)

        delta_x = pred[:, 0] - target[:, 0]
        delta_y = pred[:, 1] - target[:, 1]
        pre_angle_radian = 3.141592653589793 * pred[:, 4] / 180.0
        targrt_angle_radian = 3.141592653589793 * target[:, 4] / 180.0
        delta_angle_radian = pre_angle_radian - targrt_angle_radian

        kld =  0.5 * (
                        4 * torch.pow( ( delta_x.mul(torch.cos(targrt_angle_radian)) + delta_y.mul(torch.sin(targrt_angle_radian)) ), 2) / torch.pow(target[:, 2], 2)
                      + 4 * torch.pow( ( delta_y.mul(torch.cos(targrt_angle_radian)) - delta_x.mul(torch.sin(targrt_angle_radian)) ), 2) / torch.pow(target[:, 3], 2)
                     )\
             + 0.5 * (
                        torch.pow(pred[:, 3], 2) / torch.pow(target[:, 2], 2) * torch.pow(torch.sin(delta_angle_radian), 2)
                      + torch.pow(pred[:, 2], 2) / torch.pow(target[:, 3], 2) * torch.pow(torch.sin(delta_angle_radian), 2)
                      + torch.pow(pred[:, 3], 2) / torch.pow(target[:, 3], 2) * torch.pow(torch.cos(delta_angle_radian), 2)
                      + torch.pow(pred[:, 2], 2) / torch.pow(target[:, 2], 2) * torch.pow(torch.cos(delta_angle_radian), 2)
                     )\
             + 0.5 * (
                        torch.log(torch.pow(target[:, 3], 2) / torch.pow(pred[:, 3], 2))
                      + torch.log(torch.pow(target[:, 2], 2) / torch.pow(pred[:, 2], 2))
                     )\
             - 1.0

        kld_loss = 1 - 1 / (self.taf + torch.log(kld + 1))
        # return kld_loss
        return kld_loss.sigmoid()

class ComputeLoss_AnchorFree_Decoupled:
        # Compute losses
        def __init__(self, model, autobalance=False):
            self.sort_obj_iou = False
            device = next(model.parameters()).device  # get model device
            h = model.hyp  # hyperparameters
            self.class_index = 5 + model.nc
            self.model = model # å¤åˆ¶modelï¼Œæ–¹ä¾¿åé¢ç´¢å¼•ï¼Œadd

            # Define criteria
            # BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['cls_pw']], device=device))
            # BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['obj_pw']], device=device))
            # BCEangle = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([h['angle_pw']])).to(device)
            BCEcls = nn.BCEWithLogitsLoss(reduction="none")
            BCEobj = nn.BCEWithLogitsLoss(reduction="none")
            BCEangle = nn.BCEWithLogitsLoss(reduction="none").to(device)

            # Class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3
            self.cp, self.cn = smooth_BCE(eps=h.get('label_smoothing', 0.0))  # positive, negative BCE targets

            # Focal loss
            g = h['fl_gamma']  # focal loss gamma
            if g > 0:
                BCEcls, BCEobj = FocalLoss(BCEcls, g), FocalLoss(BCEobj, g)
                BCEangle = FocalLoss(BCEangle, g)

            # è·å–æ¯ä¸€å±‚çš„output
            det = model.module.model[-1] if is_parallel(model) else model.model[-1]  # Detect() module
            self.balance = {3: [4.0, 1.0, 0.4]}.get(det.nl, [4.0, 1.0, 0.25, 0.06, .02])  # P3-P7
            self.ssi = list(det.stride).index(16) if autobalance else 0  # stride 16 index
            self.BCEcls, self.BCEobj, self.gr, self.hyp, self.autobalance = BCEcls, BCEobj, 1.0, h, autobalance
            self.BCEangle = BCEangle
            self.iou_loss = KLDloss() # add

            # è®¾ç½®å±æ€§
            for k in 'na', 'nc', 'nl', 'anchors':
                setattr(self, k, getattr(det, k))

        def __call__(self, p, targets, imgs=None, img_path=None):  # predictions, targets, model, å¢åŠ äº†ä¸¤ä¸ªå¯è§†åŒ–å‚æ•°imgs, img_path
            '''
                @param p: list: [small_forward, medium_forward, large_forward]
                    eg:small_forward.size=( batch_size, 1ç§scaleæ¡†, size1, size2, [class,x,y,w,h,theta])
                @param targets: shape=(num_gt, [batch_size, class_id, x,y,w,h,theta])
            '''
            device = targets.device
            lcls, lbox, lobj = torch.zeros(1, device=device), torch.zeros(1, device=device), torch.zeros(1,device=device)


            # è·å–ä¸‰å±‚feature mapåˆ†åˆ«å¯¹åº”çš„åŒ¹é…æ¡†çš„å±æ€§
            cls_targets, reg_targets, angle_targets, obj_targets, anchor_mask = self.build_targets_anchor_free(p, targets)  # targets


            # å°†è¾“å‡ºçš„listè¿›è¡Œæ‹¼æ¥ï¼Œæ¯ä¸ªliståŒ…å«äº†batch_sizeä¸ªè¾“å‡º
            cls_targets = torch.cat(cls_targets, 0)
            reg_targets = torch.cat(reg_targets, 0)
            angle_targets = torch.cat(angle_targets, 0) # add (n_anchor_select_final)
            obj_targets = torch.cat(obj_targets, 0)
            anchor_masks = torch.cat(anchor_mask,0)

            # å°†outputä¹Ÿå…¨éƒ¨torch.cat
            all_outputs = torch.cat(p, 1)
            bbox_preds_with_angle = all_outputs[:, :, :5]  # [batch, anchors_all, 5]
            obj_preds = all_outputs[:, :, 5].unsqueeze(-1)  # [batch, nanchors_all, 1]
            cls_preds = all_outputs[:, :, 6:]  # [batch, anchors_all, n_cls]

            reg_targets_with_angle = torch.cat((reg_targets, angle_targets.unsqueeze(-1)), dim=1)

            '''
            eg: lossè¿™é‡Œä¸èƒ½é™¤ä»¥num_gtï¼Œå› ä¸ºnum_gtå¯èƒ½ä¸º0
            '''
            lbox += (self.iou_loss(reg_targets_with_angle, bbox_preds_with_angle.view(-1, 5)[anchor_masks])).sum() # reg_targets_with_angle.shape = (18,5), bbox_preds_with_angle.view(-1, 5).shape = (400,5)
            lcls += (self.BCEcls(cls_preds.view(-1, self.nc)[anchor_masks], cls_targets)).sum()
            lobj += (self.BCEobj(obj_preds.view(-1, 1)[anchor_masks], obj_targets[anchor_masks].float())).sum()  # obj_preds[i].shape=(total_anchors,1) obj_targets[i].shape=(total_anchors,1)
            # lobj += (self.BCEobj(obj_preds.view(-1, 1)[anchor_masks], obj_targets[anchor_masks].float())).sum()  # obj_preds[i].shape=(total_anchors,1) obj_targets[i].shape=(total_anchors,1)

            lbox *= self.hyp['box']
            lobj *= self.hyp['obj']
            lcls *= self.hyp['cls']
            reg_weight = 5.0
            # print("lbox:",lbox)
            # return (reg_weight*lbox + lobj + lcls), torch.cat((reg_weight*lbox, lobj, lcls)).detach()
            return (lbox + lobj + lcls), torch.cat((lbox, lobj, lcls)).detach() # å› ä¸º lossä¸å‚ä¸æ›´æ–°ï¼Œæ‰€ä»¥ç›´æ¥detach()

        # å°±ç±»ä¼¼äºget_assignments()æ–¹æ³•-yolox
        def build_targets_anchor_free(self, p, targets):
            '''
            @param p: list: [small_forward, medium_forward, large_forward]
                eg: small_forward.size=( batch_size, 1ç§scaleæ¡†*size1*size2, [x,y,w,h,theta,obj,classes])
            @param targets: size=(num_gt, [image_id,class,x,y,w,h,theta]), image_idè¡¨ç¤ºå½“å‰targetå±äºbatchçš„å“ªä¸€å¼ 
                eg: torch.Size = (num_gt:å½“å‰batchä¸­æ‰€æœ‰ç›®æ ‡æ•°é‡, [è¯¥imageå±äºè¯¥batchçš„ç¬¬å‡ ä¸ªå›¾ç‰‡, classId, xywh, Î˜])
            '''

            cls_targets = []
            reg_targets = []
            angle_targets = []
            obj_targets = []
            anchor_masks = []

            # è·å–é¢„æµ‹çš„è¾“å‡º
            for layer_id, pi in enumerate(p):
                # å¾—åˆ°æ¯ä¸€ä¸ªè¾“å‡ºå±‚çš„å±æ€§ï¼Œä¸€å…±ä¸‰å±‚
                # bboxes_preds = pi[:, :, 0:4] # shape = (batch, size1*size2, [x,y,w,h,theta,obj,class])
                # angle_preds = pi[:, :, 4]
                # obj_preds = pi[:, :, 5]
                # cls_preds = pi[:, :, 6:]

                # é€ä¸ªbatchçš„å¤„ç†
                for batch_id in range(pi.shape[0]):
                    # TODO:egï¼šç”±äºtargetsçš„ç¬¬äºŒä¸ªç»´åº¦ä¸­çš„ç¬¬ä¸€åˆ—æ˜¯batchçš„idï¼Œæ‰€ä»¥éœ€è¦åŠ ä¸€ä¸ªæ©è†œï¼Œæ¥ç´¢å¼•å¯¹åº”batchçš„GT
                    gt_batch_mask = (targets[:, 0] == batch_id) # gt_batch_mask.shape = (å½“å‰batchçš„num_gt, 7)
                    batch_targets = targets[gt_batch_mask] # è·å–æŸä¸€ä¸ªbatchçš„GTå€¼
                    num_gt_per_batch = batch_targets.shape[0]  # å½“å‰imageä¸­GTçš„æ•°é‡,shape = (num_gt_per_batch,[class,x,y,w,h,theta])
                    batch_pi = pi[batch_id] # å½“å‰batchä¸­çš„è¾“å‡ºï¼Œshape=(1ç§scaleæ¡†*size1*size2, [x,y,w,h,theta,obj,classes])

                    # è·å–æŸä¸€ä¸ªbatchçš„è¾“å‡º
                    bboxes_preds = batch_pi[:, 0:4]  # shape = (batch, size1*size2, [x,y,w,h,theta,obj,class])
                    angle_preds = batch_pi[:, 4]
                    obj_preds = batch_pi[:, 5]
                    cls_preds = batch_pi[:, 6:]

                    if num_gt_per_batch:
                        # TODOï¼šåˆç­›æ“ä½œ,anchor_mask.shape=(size1*size2),in_boxes_and_center.shape=(num_gt_per_batch, size1*size2)
                        anchor_mask, in_boxes_and_center = self.get_anchor_info(batch_pi, batch_targets, num_gt_per_batch, layer_index=layer_id)

                        # è·å–çœŸå®å€¼çš„ä¿¡æ¯
                        gt_bboxes = batch_targets[:num_gt_per_batch, 2:6]
                        gt_angles = batch_targets[:num_gt_per_batch, 6]
                        gt_classes = batch_targets[:num_gt_per_batch, 1] #

                        # TODOï¼šæ ¹æ®åˆç­›å¾—åˆ°çš„maskå°†ç½‘ç»œçš„è¾“å‡ºè¿›è¡Œâ€œåˆæ­¥ç­›é€‰â€
                        bboxes_preds = bboxes_preds[anchor_mask] # shape = (num_select, 4)
                        angle_preds = angle_preds[anchor_mask] # shape = (num_select,1)
                        obj_preds = obj_preds[anchor_mask]
                        cls_preds = cls_preds[anchor_mask]
                        num_in_anchor = bboxes_preds.shape[0]

                        # é¢„æµ‹çš„bbox+angleï¼ŒçœŸå®å€¼çš„bbox+angleï¼Œè¿›è¡Œconcatä¸ºåç»­ä½œlossåšå‡†å¤‡
                        gt_bboxes_with_angle = torch.cat((gt_bboxes, gt_angles.unsqueeze(1)), dim=1) # shape=ï¼ˆnum_gtï¼Œ4+1ï¼‰
                        pred_bboxes_with_angle = torch.cat((bboxes_preds,angle_preds.unsqueeze(1)), dim=1)# shape=ï¼ˆnum_selectï¼Œ4+1ï¼‰

                        # TODO: å°†åˆæ­¥ç­›é€‰çš„bboxï¼ˆnum_select,5)ä¸çœŸå®å€¼ï¼ˆnum_gt,5ï¼‰ä½œloss
                        # pairwise_iou_loss.shape = (num_in_anchor, num_select)
                        pairwise_iou_loss = self.compute_kld_loss(pred_bboxes_with_angle, gt_bboxes_with_angle)
                        pairwise_iou_approximate = 1.0 - pairwise_iou_loss # å–lossçš„è¿‘ä¼¼å€¼

                        # å°†ä½¿ç”¨F.one_hotå°†æ ‡ç­¾çš„ç»´åº¦è½¬åŒ–ä¸ºä¸é¢„æµ‹å€¼çš„ç»´åº¦ä¸€æ ·çš„çŸ©é˜µ
                        gt_cls_per_image = (
                            F.one_hot(gt_classes.to(torch.int64), self.nc) # shape=(num_gt, 16)
                            .float()
                            .unsqueeze(1) # shape = (num_gt,1,16)
                            .repeat(1, num_in_anchor, 1) # shape = (num_gt,num_in_anchor,16)
                        )
                        
                        # å¤„ç†é¢„æµ‹çš„cls, clsçš„æ¡ä»¶æ¦‚ç‡å’Œobjçš„å…ˆéªŒæ¦‚ç‡åšä¹˜ç§¯ï¼Œå¾—åˆ°ç›®æ ‡çš„ç±»åˆ«åˆ†æ•°ã€‚
                        cls_preds = (
                            cls_preds.float().unsqueeze(0).repeat(num_gt_per_batch, 1, 1).sigmoid_()
                            * obj_preds.unsqueeze(1).unsqueeze(0).repeat(num_gt_per_batch, 1, 1).sigmoid_()
                        ) # cls_preds shape: (n_gt, n_anchor_select, 16)

                        # å°†æ‰€æœ‰çš„æ ‡ç­¾å€¼clsä¸æ‰€æœ‰å€™é€‰æ¡†çš„clsè¿›è¡Œåšäº¤å‰ç†µæŸå¤±
                        pairwise_cls_loss = F.binary_cross_entropy_with_logits(cls_preds.sqrt_(), gt_cls_per_image, reduction="none").sum(-1)  # cls_preds_ shape: (n_gt, n_anchor_select)
                        del cls_preds

                        # è®©ä¸­å¿ƒä¸åœ¨æ ‡æ³¨æ¡†é‡Œæˆ–è€…ä¸­å¿ƒä¸åœ¨5*5æ–¹æ ¼é‡Œçš„é”šæ¡†costå€¼å¾ˆå¤§
                        # è¿™é‡Œåšæˆæœ¬è®¡ç®—ï¼Œå³ã€åˆ†ç±»æŸå¤±ã€‘å’Œã€å›å½’æŸå¤±ã€‘
                        cost = (pairwise_cls_loss + 3.0 * pairwise_iou_loss+ 100000.0 * (~in_boxes_and_center))
            
                        # è¿™é‡Œå¼•å…¥SIMOTAç­–ç•¥ï¼ˆæ—·ä¸–ï¼‰
                        #     1.é¦–å…ˆè®¾ç½®å€™é€‰æ¡†çš„æ•°é‡ï¼Œè¿™é‡Œä¼šæ–°å»ºä¸€ä¸ªçŸ©é˜µï¼Œshape=(num_gt, num_select)ï¼›
                        #     2.é€šè¿‡costæˆæœ¬æŒ‘é€‰å€™é€‰æ¡†ï¼Œç„¶åé€šè¿‡topk_iousç­›é€‰çš„ä¿¡æ¯ï¼ŒåŠ¨æ€çš„é€‰æ‹©å€™é€‰æ¡†ï¼›
                        # return :
                        #     è¿”å›åŒ¹é…åˆ°çš„é¢„æµ‹æ¡†æ•°é‡ï¼ŒåŒ¹é…åˆ°çš„cls, åŒ¹é…åˆ°çš„iou,åŒ¹é…åˆ°çš„gtçš„index
                        #     num_matched_anchors, matched_classes_per_gt,matched_ious_per_gt, matched_gt_index

                        # TODO: self.dynamic_k_matching()è¯¥æ–¹æ³•ç›®å‰æœ‰bug
                        (num_matched_anchors, matched_classes_per_gt, matched_ious_per_gt, matched_gt_index, mask_in_boxes)=self.dynamic_k_matching(cost, pairwise_iou_approximate, gt_classes, num_gt_per_batch, anchor_mask)


                        cls_target = F.one_hot(matched_classes_per_gt.to(torch.int64), self.nc) * matched_ious_per_gt.unsqueeze(-1)# (num_select_final, self.nc)
                        obj_target = anchor_mask.unsqueeze(-1)  # ï¼ˆn_anchor_select_final, 1ï¼‰
                        # obj_target = mask_in_boxes.unsqueeze(-1)  # ï¼ˆn_anchor_select_final, 1ï¼‰
                        reg_target = gt_bboxes[matched_gt_index]  # (n_anchor_select_final, 4)
                        angle_target = gt_angles[matched_gt_index]  # add  ï¼ˆn_anchor_select_finalï¼‰

                        # ç›´æ¥ç”¨åˆæ­¥ç­›é€‰å¾—åˆ°çš„æ­£æ ·æœ¬è¿›è¡Œå›å½’å’Œåˆ†ç±»
                    else:
                        cls_target = pi.new_zeros((0, self.nc))
                        reg_target = pi.new_zeros((0, 4))
                        angle_target = pi.new_zeros(0)
                        obj_target = pi.new_zeros((pi.shape[1], 1))
                        anchor_mask = pi.new_zeros(pi.shape[1]).bool()
                    cls_targets.append(cls_target)
                    reg_targets.append(reg_target)
                    angle_targets.append(angle_target)  # add
                    obj_targets.append(obj_target)
                    anchor_masks.append(anchor_mask)

            return cls_targets, reg_targets, angle_targets, obj_targets, anchor_masks

        '''
        åŠŸèƒ½ï¼šåˆæ­¥ç­›é€‰æ­£æ ·æœ¬çš„anchorï¼Œä¸ºç²¾ç»†åŒ–ç­›é€‰åšå‡†å¤‡
        '''
        def get_anchor_info(self, pi, targets, num_gt_per_batch, layer_index):
            '''
            @param pi: ä¼ å…¥çš„æ˜¯batchä¸­æŸä¸€ä¸ªçš„ç‰¹å¾å›¾ï¼Œsize = (1ç§scaleæ¡† * size1 * size2, [x,y,w,h,theta,obj,classes])
                eg: å°†æ£€æµ‹å¤´çš„æ¯ä¸€å±‚è¾“å‡ºçš„ç‰¹å¾å›¾wï¼Œhè¿›è¡Œåˆå¹¶
            @param targets: å½“å‰batchä¸­æŸä¸€ä¸ªimageçš„targetsï¼Œshape=(num_gt_per_batch, [class,x,y,w,h,theta])
            '''
            exp_strides = []  # ä¿å­˜é‡‡æ ·ç‡
            strides = [8, 16, 32]  # ä¸‰å±‚layerçš„é‡‡æ ·ç‡
            num_anchor, num_gt_per_batch = self.na, num_gt_per_batch  # é¢„æµ‹æ¡†çš„ç§ç±», å½“å‰imageä¸­æ ‡ç­¾å€¼çš„æ•°é‡

            # è¿”å›æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„æ­£æ ·æœ¬anchorï¼Œå®ƒæ˜¯ä¸€ä¸ªlistï¼Œsize=3
            boxes_or_center = []
            boxes_and_center = []

            # åˆå§‹åŒ–ç½‘æ ¼ç©ºé—´çš„ç¼©æ”¾å¢ç›Š
            gain = torch.ones(7, device=targets.device)
            xx = [1,int(np.sqrt(pi.shape[0])), int(np.sqrt(pi.shape[0])), 1] # (w,h,22)
            gain[2:6] = torch.tensor(xx)[[2, 1, 2, 1]]  # ç‰¹å¾å›¾çš„w,h,w,h

            # targets: size=(num_anchor, num_gt,[image,class_id,x,y,w,h,theta])
            t = targets * gain  # å°†æ ‡ç­¾å€¼ç¼©æ”¾åˆ°ç‰¹å¾å›¾ä¸Š

            # æ‰€æœ‰çš„anchoræ•°é‡
            total_num_anchors = pi.shape[0]

            # è·å–gridçš„x,yåæ ‡
            if RANK !=-1: # DDP
                x_shifts = self.model.module.model[-1].grid[layer_index][:, :, 0]
                y_shifts = self.model.module.model[-1].grid[layer_index][:, :, 1]
            else:
                x_shifts = self.model.model[-1].grid[layer_index][:, :, 0] # shape = (1, size1*size2)
                y_shifts = self.model.model[-1].grid[layer_index][:, :, 1]

            # exp_stride: ä¿å­˜æ¯ä¸€å±‚çš„é‡‡æ ·é—´éš”ï¼Œsize=(1, grid.shape[1])
            exp_strides = torch.zeros(1, pi.shape[0]).fill_(strides[layer_index]).type_as(pi[0])

            # è·å–æ¯ä¸ªç‰¹å¾å›¾çš„x,yæ ¼ç‚¹åæ ‡
            # x_shifts_per_img = x_shifts * exp_strides[layer_index]
            # y_shifts_per_img = y_shifts * exp_strides[layer_index]
            x_shifts_per_img = x_shifts[0]  * exp_strides
            y_shifts_per_img = y_shifts[0]  * exp_strides

            # è·å–æ¯ä¸ªæ ¼ç‚¹çš„ä¸­å¿ƒåæ ‡,å·¦ä¸Šè§’ä¸ºåŸç‚¹
            # x_c_per_img.shape = [num_gt_per_batch, total_num_anchors]
            x_c_per_img = ((x_shifts_per_img + 0.5 * exp_strides).repeat(num_gt_per_batch, 1))
            y_c_per_img = ((y_shifts_per_img + 0.5 * exp_strides).repeat(num_gt_per_batch, 1))

            # TODOï¼šåˆæ­¥ç­›é€‰
            # è®¡ç®—æ ‡ç­¾çš„å·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡ï¼Œå³ï¼ˆ[left,top], [right,bottom])
            # gt_xxxä¸x_c_per_imgç»´åº¦åº”è¯¥ç›¸åŒ
            # gt_l = ( (t[: , :, 2] - 0.5 * t[:, :, 4]).squeeze(1).repeat(1,total_num_anchors))
            # gt_t = ( (t[: , :, 3] - 0.5 * t[:, :, 5]).squeeze(1).repeat(1,total_num_anchors))
            # gt_r = ( (t[: , :, 2] + 0.5 * t[:, :, 4]).squeeze(1).repeat(1,total_num_anchors))
            # gt_b = ( (t[: , :, 3] + 0.5 * t[:, :, 5]).squeeze(1).repeat(1,total_num_anchors))
            gt_l = ((t[:, 2] - 0.5 * t[:, 4]).unsqueeze(1).repeat(1, total_num_anchors)) # shape=(num_gt_per_img, total_anchors)
            gt_t = ((t[:, 3] - 0.5 * t[:, 5]).unsqueeze(1).repeat(1, total_num_anchors))
            gt_r = ((t[:, 2] + 0.5 * t[:, 4]).unsqueeze(1).repeat(1, total_num_anchors))
            gt_b = ((t[:, 3] + 0.5 * t[:, 5]).unsqueeze(1).repeat(1, total_num_anchors))

            # TODO ï¼šanchor freeçš„æ€è·¯æ˜¯æ¯ä¸ªæ ¼ç‚¹éƒ½ä½œä¸ºä¸€ä¸ªé¢„æµ‹çš„anchorï¼Œå› æ­¤anchoræ•°é‡å°±æ˜¯å½“å‰çš„ç‰¹å¾å›¾å¤§å°;
            # è®¡ç®—å‡ºæ¯ä¸ªanchorçš„å·¦ä¸Šè§’å’Œå³ä¸Šè§’åæ ‡ï¼ˆå·¦ä¸Šè§’ä¸ºåŸç‚¹ï¼‰ï¼Œç„¶åä¸çœŸå®çš„æ ‡ç­¾å€¼è¿›è¡Œåˆ¤æ–­â€œå½“å‰anchoræ˜¯å¦å¤„äºGTçš„å†…éƒ¨â€ï¼šå¦‚æœæ˜¯åˆ™ä¸ºæ­£æ ·æœ¬
            bbox_l = x_c_per_img - gt_l
            bbox_r = gt_r - x_c_per_img
            bbox_t = y_c_per_img - gt_t
            bbox_b = gt_b - y_c_per_img
            bboxes = torch.stack([bbox_l, bbox_t, bbox_r, bbox_b], 2)  # size = (num_gt, feature_size1*feature_size2,4)

            # ç„¶åå°†æ‰€æœ‰è½åœ¨GTä¸­çš„anchoræŒ‘é€‰å‡ºæ¥
            in_boxes = bboxes.min(dim=-1).values > 0.0  # å¿…é¡»å…¨éƒ¨å¤§äº0æ‰æ˜¯éœ€è¦çš„anchor
            in_boxes_all = in_boxes.sum(dim=0) > 0  # ä¸­å¿ƒç‚¹ä½äºæ ‡æ³¨æ¡†å†…çš„é”šæ¡†ä¸ºTrue,ç›¸å½“äºä¸€ä¸ªmask

            # TODO å†æ¬¡ç­›é€‰ï¼šç»˜åˆ¶ä¸€ä¸ªè¾¹é•¿ä¸º5çš„æ­£æ–¹å½¢ã€‚å·¦ä¸Šè§’ç‚¹ä¸ºï¼ˆgt_lï¼Œgt_tï¼‰ï¼Œå³ä¸‹è§’ç‚¹ä¸ºï¼ˆgt_rï¼Œgt_bï¼‰ã€‚gtä»¥æ­£æ–¹å½¢èŒƒå›´å½¢å¼å»æŒ‘é€‰é”šæ¡†
            radius = 2  # åŠå¾„
            # gt_l = (targets[:, 2].unsqueeze(1).repeat(1, total_num_anchors)) - radius * exp_strides[i]# x - radius*stride
            # gt_r = (targets[:, 2].unsqueeze(1).repeat(1, total_num_anchors)) + radius * exp_strides[i]
            # gt_t = (targets[:, 3].unsqueeze(1).repeat(1, total_num_anchors)) - radius * exp_strides[i]
            # gt_b = (targets[:, 3].unsqueeze(1).repeat(1, total_num_anchors)) + radius * exp_strides[i]
            gt_l = (t[:, 2].unsqueeze(1).repeat(1, total_num_anchors)) - radius * exp_strides  # x - radius*stride
            gt_t = (t[:, 3].unsqueeze(1).repeat(1, total_num_anchors)) - radius * exp_strides
            gt_r = (t[:, 2].unsqueeze(1).repeat(1, total_num_anchors)) + radius * exp_strides
            gt_b = (t[:, 3].unsqueeze(1).repeat(1, total_num_anchors)) + radius * exp_strides
            # gt_b = (t[:, :, 3].squeeze(0).unsqueeze(1).repeat(1, total_num_anchors)) + radius * exp_strides[layer_index]

            c_l = x_c_per_img - gt_l
            c_r = gt_r - x_c_per_img
            c_t = y_c_per_img - gt_t
            c_b = gt_b - y_c_per_img
            center = torch.stack([c_l, c_t, c_r, c_b], 2)
            in_centers = center.min(dim=-1).values > 0.0
            in_centers_all = in_centers.sum(dim=0) > 0

            # æŸä¸€è¾¹åœ¨gté‡Œé¢
            # boxes_or_center.append(in_boxes_all | in_centers_all)
            boxes_or_center = in_boxes_all | in_centers_all #é listç‰ˆæœ¬

            # ä¸¤è€…éƒ½åœ¨gté‡Œé¢
            # boxes_and_center.append(in_boxes[:, boxes_or_center[i]] & in_centers[:, boxes_or_center[i]])
            boxes_and_center= in_boxes[:, boxes_or_center] & in_centers[:, boxes_or_center] #é listç‰ˆæœ¬

            return boxes_or_center, boxes_and_center


        def compute_kld_loss(self,p, targets, taf = 1.0):
            '''
            @param p: é€šè¿‡get_anchor_infoï¼ˆï¼‰çš„maskåˆç­›å¾—åˆ°çš„æ­£æ ·æœ¬ï¼Œshape=(num_select, xywh+angle)
            @param targets: æ ‡ç­¾å€¼, shape = (num_gt, xywh,angle)
            @return
            '''
            with torch.no_grad():
                # åˆå§‹åŒ–æ ‡ç­¾å€¼ï¼Œä¸€ä¸ªzeroçŸ©é˜µï¼Œshape=(0,num_select)
                kld_loss_ = torch.zeros(0, p.shape[0], device=targets.device)
                for t in targets: # å°†æ¯ä¸€ä¸ªçœŸå®å€¼ä¸åˆç­›å¾—åˆ°çš„æ­£æ ·æœ¬è¿›è¡ŒæŸå¤±è®¡ç®—
                    t = t.unsqueeze(0).repeat(p.shape[0],1) # t.shape = (num_select, num_gt, 5)
                    kld_loss = self.kld_loss(p, t)
                    kld_loss_ = torch.cat((kld_loss_, kld_loss.unsqueeze(0)), dim=0)

            return kld_loss_

        # è¿™é‡ŒæŸå¤±çš„è®¡ç®—å¯ä»¥æ›¿æ¢ï¼Œadd
        def kld_loss(self, p, t, taf = 1.0):
            '''
            @param p: é€šè¿‡get_anchor_infoï¼ˆï¼‰çš„maskåˆç­›å¾—åˆ°çš„æ­£æ ·æœ¬ï¼Œshape=(num_select,5)
            @param targets: æ ‡ç­¾å€¼, shape = (num_select, num_gt, 5)
            '''
            assert p.shape[0] == t.shape[0] # æ–­è¨€æ“ä½œ
            p = p.view(-1,5)
            t = t.view(-1,5)

            delta_x = p[:, 0] - t[:, 0]
            delta_y = p[:, 1] - t[:, 1]

            # è§’åº¦è½¬å¼§åº¦ï¼Œeg: æ ‡ç­¾å’Œé¢„æµ‹çš„angleéƒ½æ˜¯è§’åº¦ï¼Œéœ€è¦è¿›è¡Œè½¬åŒ–ï¼Œç„¶åä½œåæ ‡çš„ä¸‰è§’å‡½æ•°å˜æ¢
            p_angle_radian = 3.1415926535897932 * p[:, 4] / 180.0
            t_angle_radian = 3.1415926535897932 * t[:, 4] / 180.0
            delta_angle_radian = p_angle_radian - t_angle_radian

            # è¿›è¡Œå¸¦è§’åº¦çš„æŸå¤±å‡½æ•°è®¡ç®—
            kld = \
            0.5 * (
                  4 * torch.pow((delta_x.mul(torch.cos(t_angle_radian)) + delta_y.mul(torch.sin(t_angle_radian))),2) / torch.pow(t[:, 2], 2)
                + 4 * torch.pow((delta_y.mul(torch.cos(t_angle_radian)) - delta_x.mul(torch.sin(t_angle_radian))),2) / torch.pow(t[:, 3], 2)
            ) \
            + 0.5 * (
                    torch.pow(p[:, 3], 2) / torch.pow(t[:, 2], 2) * torch.pow(torch.sin(delta_angle_radian), 2)
                  + torch.pow(p[:, 2], 2) / torch.pow(t[:, 3], 2) * torch.pow(torch.sin(delta_angle_radian), 2)
                  + torch.pow(p[:, 3], 2) / torch.pow(t[:, 3], 2) * torch.pow(torch.cos(delta_angle_radian), 2)
                  + torch.pow(p[:, 2], 2) / torch.pow(t[:, 2], 2) * torch.pow(torch.cos(delta_angle_radian), 2)
            ) \
            + 0.5 * (
                      torch.log(torch.pow(t[:, 3], 2) / torch.pow(p[:, 3], 2))
                    + torch.log(torch.pow(t[:, 2], 2) / torch.pow(p[:, 2], 2))
              ) - 1.0

            kld_loss = 1 - 1 / (taf + torch.log(kld + 1))
            return kld_loss
            # return kld_loss.sigmoid()

        # æ—·ä¸–æå‡ºçš„SimOTAç­–ç•¥ï¼Œä¼šå¼•å…¥é¢å¤–å¤æ‚åº¦
        def dynamic_k_matching(self, cost, pairwise_iou_approximate, gt_classes, num_gt, anchor_mask):
            # åˆ›å»ºä¸€ä¸ªçŸ©é˜µï¼Œshape=(num_gt, num_select)
            matching_matrix = torch.zeros_like(cost)

            iou_in_boxes = pairwise_iou_approximate # shape(num_gt, num_select)
            # TODOï¼š1.è®¾ç½®å‰Kä¸ªå€™é€‰æ¡†,æºä»£ç k=10ï¼Œè¿™é‡Œè€ƒè™‘åˆ°é€Ÿåº¦é—®é¢˜å–5
            top_k_anchor = min(10, iou_in_boxes.size(1))

            # ç„¶åç»™æ¯ä¸ªç›®æ ‡æŒ‘é€‰å‰Kä¸ªå€™é€‰æ¡†ï¼Œtopk_anchor_per_gt.shape = (num_gt, k)
            # topk_anchor_per_gté‡Œé¢å­˜å‚¨äº†æ¯ä¸ªGTå¯¹åº”çš„Kä¸ªæ¡†çš„æ¦‚ç‡
            topk_anchor_per_gt, _ = torch.topk(iou_in_boxes, top_k_anchor, dim=1)

            '''
                eg: torch.topk(input, k, dim=None, largest=True, sorted=True, out=None) :
                    åŠŸèƒ½ï¼šæ²¿ç€ç»™å®šçš„ç»´åº¦ï¼Œè¿”å›è¾“å…¥çš„å¼ é‡ä¸­å‰Kä¸ªæœ€å¤§å€¼ï¼Œå¦‚æœä¸æŒ‡å®šç»´åº¦ï¼Œåˆ™é»˜è®¤è¿”å›æœ€åä¸€ä¸ªç»´åº¦ï¼›
                    k: è¿”å›çš„å‰Kä¸ªï¼›
                    largeï¼šTrue-è¿”å›å‰Kä¸ªæœ€å¤§å€¼ï¼ŒFalse-è¿”å›å‰Kä¸ªæœ€å°å€¼
                    returnï¼šä¸€ä¸ªå…ƒç»„
            '''
            dynamic_k = torch.clamp(topk_anchor_per_gt.sum(1).int(), min=1) # topk_anchor_per_gt.sum(1).int():å‡è®¾è¯¥çŸ©é˜µç»´åº¦=(3,5)ï¼Œåˆ™æŠŠæ¯ä¸€è¡Œè¿›è¡Œç›¸åŠ æœ€åå¾—åˆ°ä¸€åˆ—3è¡Œçš„æ•°æ®ï¼Œè¿™æ ·å°±å¾—åˆ°äº†æ¯ä¸ªgtå¯¹åº”çš„å€™é€‰æ¡†æœ€å¤§å€¼
            for gt_id in range(num_gt):
                # TODOï¼š2.é€šè¿‡costæ¥æŒ‘é€‰å€™é€‰æ¡†
                # è¿™é‡Œå°±ç›¸å½“äºç»™æ¯ä¸ªgtåŠ¨æ€çš„åˆ†é…å€™é€‰æ¡†ï¼Œå…¶ä¸­è¢«åˆ†é…åˆ°çš„å€™é€‰æ¡†çš„ç´¢å¼•ä¼šè®°å½•åˆ°â€œmatching_matrixâ€œçŸ©é˜µä¸­ï¼Œå¯¹åº”ä½ç½®=1
                try:
                    _, res = torch.topk(cost[gt_id], k=dynamic_k[gt_id].item(), largest=False)
                    matching_matrix[gt_id][res] = 1.0
                except Exception as e:
                    print(cost.shape)
                    print(dynamic_k[gt_id].item())
                # _, res = torch.topk(cost[gt_id], k=dynamic_k[gt_id].item(), largest=False)
                # matching_matrix[gt_id][res] = 1.0
            # del topk_anchor_per_gt, dynamic_k, res

            # TODOï¼š3.è¿‡æ»¤å…±ç”¨çš„å€™é€‰æ¡†ï¼Œå³çŸ©é˜µä¸­åŒä¸€åˆ—æœ‰å¤šä¸ª1é‚£ç§ï¼Œå¦‚æœæœ‰ä¸€ä¸ªå€™é€‰æ¡†è¢«å¤šä¸ªâ€ç›®æ ‡â€œé€‰ä¸­ï¼Œè¿™æ—¶å€™è¦æ¯”è¾ƒå…¶å¯¹åº”çš„costå€¼ï¼Œè¾ƒå°çš„å€¼ä¿ç•™å€™é€‰æ¡†
            # TODOï¼šå¦‚æœå­˜åœ¨costå€¼ç›¸ç­‰çš„è¯¥æ€ä¹ˆåŠï¼Ÿ
            anchor_matching_gt = matching_matrix.sum(0)
            if (anchor_matching_gt > 1).sum() > 0: # anchor_matching_gt > 1è¡¨ç¤ºå­˜åœ¨äºŒä¹‰æ€§çš„å€™é€‰æ¡†
                _, cost_argmin = torch.min(cost[:, anchor_matching_gt > 1], dim=0)# å°†costä¸­ï¼Œç¬¬å¯¹åº”åˆ—çš„å€¼å–å‡ºï¼Œå¹¶è¿›è¡Œæ¯”è¾ƒï¼Œè®¡ç®—æœ€å°å€¼æ‰€å¯¹åº”çš„è¡Œæ•°ï¼Œä»¥åŠåˆ†æ•°ã€‚
                matching_matrix[:, anchor_matching_gt > 1] *= 0.0 # å°†å¯¹åº”ä½ç½®è®¾ç½®ä¸º0
                matching_matrix[cost_argmin, anchor_matching_gt > 1] = 1.0 # å°†å¯¹åº”ä½ç½®è®¾ç½®ä¸º1

            mask_in_boxes = matching_matrix.sum(0) > 0.0
            num_matched_anchors = mask_in_boxes.sum().item()  # è¢«åŒ¹é…åˆ°çš„é¢„æµ‹æ¡†çš„æ•°é‡

            anchor_mask[anchor_mask.clone()] = mask_in_boxes #è¢«æŒ‘é€‰çš„é¢„æµ‹æ¡†å¯¹åº”çš„ä½ç½®èµ‹å€¼ä¸ºTrueï¼Œshape=(num_matched_anchors)

            # bug-test
            matched_gt_index = matching_matrix[:, mask_in_boxes].argmax(0)

            matched_classes_per_gt = gt_classes[matched_gt_index]  # åœ¨çœŸå®å€¼ä¸­è¢«é¢„æµ‹æ¡†åŒ¹é…åˆ°çš„ç±»åˆ«ï¼Œshapeï¼ˆnum_matched_anchorsï¼‰

            matched_ious_per_gt = (matching_matrix * pairwise_iou_approximate).sum(0)[mask_in_boxes]  # è¢«åŒ¹é…ä¸Šçš„é¢„æµ‹æ¡†å’Œæ ‡æ³¨æ¡†çš„iou,shapeï¼ˆnum_matched_anchorsï¼‰

            # è¿”å›åŒ¹é…åˆ°çš„é¢„æµ‹æ¡†æ•°é‡ï¼ŒåŒ¹é…åˆ°çš„cls, åŒ¹é…åˆ°çš„iou,åŒ¹é…åˆ°çš„gtçš„index
            return num_matched_anchors, matched_classes_per_gt,matched_ious_per_gt, matched_gt_index, mask_in_boxes

# TODOï¼šå°†åŸºäºShapeçš„ç­›é€‰ç­–ç•¥ä¿®æ”¹ä¸ºâ€œä¸­å¿ƒç‚¹ç­–ç•¥â€ï¼ŒåŒæ—¶è€ƒè™‘åŠ ä¸Šé¢å¤–çš„æƒ©ç½šæœºåˆ¶
class ComputeLoss_AnchorFree_Decoupled_CenterPoint:
    # Compute losses
    def __init__(self, model, autobalance=False, hyp=None): # add hyp for debug, 2021å¹´11æœˆ25æ—¥11:19:51
        self.sort_obj_iou = False
        device = next(model.parameters()).device  # get model device # TODOï¼š debugæ—¶æ³¨é”€

        # h = model.hyp  # hyperparameters
        h = hyp  # hyperparameters
        # self.class_index = 5 + model.nc
        self.class_index = 5 + 16
        self.model = model  # å¤åˆ¶modelï¼Œæ–¹ä¾¿åé¢ç´¢å¼•ï¼Œadd

        # Define criteria
        # BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['cls_pw']], device=device))
        # BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['obj_pw']], device=device))
        # BCEangle = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([h['angle_pw']])).to(device)
        BCEcls = nn.BCEWithLogitsLoss(reduction="none")
        BCEobj = nn.BCEWithLogitsLoss(reduction="none")
        BCEangle = nn.BCEWithLogitsLoss(reduction="none").to(device)
        # BCEangle = nn.BCEWithLogitsLoss(reduction="none")


        # Class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3
        self.cp, self.cn = smooth_BCE(eps=h.get('label_smoothing', 0.0))  # positive, negative BCE targets

        # Focal loss
        g = h['fl_gamma']  # focal loss gamma
        if g > 0:
            BCEcls, BCEobj = FocalLoss(BCEcls, g), FocalLoss(BCEobj, g)
            BCEangle = FocalLoss(BCEangle, g)
            logging.info("use FocalLoss loss")

        # add, use l1 loss
        # if h['use_l1'] > 0:
        #     BCEcls = nn.L1Loss(reduction="none") # æ·»åŠ L1 loss
        #     BCEobj = nn.L1Loss(reduction="none") # æ·»åŠ L1 loss
        #     logging.info("use L1 loss")

        # è·å–æ¯ä¸€å±‚çš„output
        det = model.module.model[-1] if is_parallel(model) else model.model[-1]  # Detect() module
        self.balance = {3: [4.0, 1.0, 0.4]}.get(det.nl, [4.0, 1.0, 0.25, 0.06, .02])  # P3-P7
        self.ssi = list(det.stride).index(16) if autobalance else 0  # stride 16 index
        self.BCEcls, self.BCEobj, self.gr, self.hyp, self.autobalance = BCEcls, BCEobj, 1.0, h, autobalance
        self.BCEangle = BCEangle
        self.iou_loss = KLDloss()  # add

        # è®¾ç½®å±æ€§
        for k in 'na', 'nc', 'nl', 'anchors':
            setattr(self, k, getattr(det, k))

    def __call__(self, p, targets, imgs=None, img_path=None):  # predictions, targets, model, å¢åŠ äº†ä¸¤ä¸ªå¯è§†åŒ–å‚æ•°imgs, img_path
        '''
            @param p: list: [small_forward, medium_forward, large_forward]
                eg:small_forward.size=( batch_size, 1ç§scaleæ¡†, size1, size2, [class,x,y,w,h,theta])
            @param targets: shape=(num_gt, [batch_size, class_id, x,y,w,h,theta])
        '''
        device = targets.device
        lcls, lbox, lobj = torch.zeros(1, device=device), torch.zeros(1, device=device), torch.zeros(1, device=device)

        # è·å–ä¸‰å±‚feature mapåˆ†åˆ«å¯¹åº”çš„åŒ¹é…æ¡†çš„å±æ€§
        cls_targets, reg_targets, angle_targets, obj_targets, anchor_masks = self.build_targets_anchor_free(p,
                                                                                                           targets)  # targets

        # å°†è¾“å‡ºçš„listè¿›è¡Œæ‹¼æ¥ï¼Œæ¯ä¸ªliståŒ…å«äº†batch_sizeä¸ªè¾“å‡º
        cls_targets = torch.cat(cls_targets, 0)
        reg_targets = torch.cat(reg_targets, 0)
        angle_targets = torch.cat(angle_targets, 0)  # add (n_anchor_select_final)
        obj_targets = torch.cat(obj_targets, 0)
        anchor_masks = torch.cat(anchor_masks, 0)

        # å°†outputä¹Ÿå…¨éƒ¨torch.cat
        all_outputs = torch.cat(p, 1)
        bbox_preds_with_angle = all_outputs[:, :, :5]  # [batch, anchors_all, 5]
        obj_preds = all_outputs[:, :, 5].unsqueeze(-1)  # [batch, anchors_all, 1]
        cls_preds = all_outputs[:, :, 6:]  # [batch, anchors_all, n_cls]

        reg_targets_with_angle = torch.cat((reg_targets, angle_targets.unsqueeze(-1)), dim=1)

        '''
        1.è®¡ç®—lossï¼Œiouéƒ¨åˆ†çš„lossæ·»åŠ äº†è§’åº¦è®¡ç®—
        '''
        # num_gt = max(targets.shape[0],1)
        num_gt = targets.shape[0]
        if num_gt:
            # lbox += (self.iou_loss(reg_targets_with_angle, bbox_preds_with_angle.view(-1, 5)[anchor_masks])).sum() / num_gt # reg_targets_with_angle.shape = (18,5), bbox_preds_with_angle.view(-1, 5).shape = (400,5)
            lbox += (self.giou_loss(p_box=reg_targets_with_angle, t_box=bbox_preds_with_angle.view(-1, 5)[anchor_masks])).sum() / num_gt # reg_targets_with_angle.shape = (18,5), bbox_preds_with_angle.view(-1, 5).shape = (400,5)
            lcls += (self.BCEcls(cls_preds.view(-1, self.nc)[anchor_masks], cls_targets.to(torch.float32))).sum() / num_gt
            lobj += (self.BCEobj(obj_preds.view(-1, 1)[anchor_masks], obj_targets[anchor_masks].float())).sum() / num_gt  # obj_preds[i].shape=(total_anchors,1) obj_targets[i].shape=(total_anchors,1)

            # lobj += (self.BCEobj(obj_preds.view(-1, 1)[anchor_masks], obj_targets[anchor_masks].float())).sum()  # obj_preds[i].shape=(total_anchors,1) obj_targets[i].shape=(total_anchors,1)
            # lbox *= self.hyp['box']
            # lobj *= self.hyp['obj']
            # lcls *= self.hyp['cls']
            # reg_weight = 5.0
            # print("lbox:",lbox)
        # return (reg_weight*lbox + lobj + lcls), torch.cat((reg_weight*lbox, lobj, lcls)).detach()
        return (lbox + lobj + lcls), torch.cat((lbox, lobj, lcls)).detach()  # å› ä¸º lossä¸å‚ä¸æ›´æ–°ï¼Œæ‰€ä»¥ç›´æ¥detach()

    # å°±ç±»ä¼¼äºget_assignments()æ–¹æ³•-yolox
    def build_targets_anchor_free(self, p, targets):
        '''
        @param p: list: [small_forward, medium_forward, large_forward]
            eg: small_forward.size=( batch_size, 1ç§scaleæ¡†*size1*size2, [x,y,w,h,theta,obj,classes])
        @param targets: size=(num_gt, [image_id,class,x,y,w,h,theta]), image_idè¡¨ç¤ºå½“å‰targetå±äºbatchçš„å“ªä¸€å¼ 
            eg: torch.Size = (num_gt:å½“å‰batchä¸­æ‰€æœ‰ç›®æ ‡æ•°é‡, [è¯¥imageå±äºè¯¥batchçš„ç¬¬å‡ ä¸ªå›¾ç‰‡, classId, xywh, Î˜])
        '''

        cls_targets = []
        reg_targets = []
        angle_targets = []
        obj_targets = []
        anchor_masks = []

        # è·å–é¢„æµ‹çš„è¾“å‡º
        for layer_id, pi in enumerate(p):
            # å¾—åˆ°æ¯ä¸€ä¸ªè¾“å‡ºå±‚çš„å±æ€§ï¼Œä¸€å…±ä¸‰å±‚
            # bboxes_preds = pi[:, :, 0:4] # shape = (batch, size1*size2, [x,y,w,h,theta,obj,class])
            # angle_preds = pi[:, :, 4]
            # obj_preds = pi[:, :, 5]
            # cls_preds = pi[:, :, 6:]

            # é€ä¸ªbatchçš„å¤„ç†
            for batch_id in range(pi.shape[0]):
                # TODO:egï¼šç”±äºtargetsçš„ç¬¬äºŒä¸ªç»´åº¦ä¸­çš„ç¬¬ä¸€åˆ—æ˜¯batchçš„idï¼Œæ‰€ä»¥éœ€è¦åŠ ä¸€ä¸ªæ©è†œï¼Œæ¥ç´¢å¼•å¯¹åº”batchçš„GT
                gt_batch_mask = (targets[:, 0] == batch_id)  # gt_batch_mask.shape = (å½“å‰batchçš„num_gt, 7)
                batch_targets = targets[gt_batch_mask]  # è·å–æŸä¸€ä¸ªbatchçš„GTå€¼
                num_gt_per_batch = batch_targets.shape[
                    0]  # å½“å‰imageä¸­GTçš„æ•°é‡,shape = (num_gt_per_batch,[class,x,y,w,h,theta])
                batch_pi = pi[batch_id]  # å½“å‰batchä¸­çš„è¾“å‡ºï¼Œshape=(1ç§scaleæ¡†*size1*size2, [x,y,w,h,theta,obj,classes])

                # è·å–æŸä¸€ä¸ªbatchçš„è¾“å‡º
                bboxes_preds = batch_pi[:, 0:4]  # shape = (batch, size1*size2, [x,y,w,h,theta,obj,class])

                if num_gt_per_batch:
                    # TODOï¼šåˆç­›æ“ä½œ,anchor_mask.shape=(size1*size2),in_boxes_and_center.shape=(num_gt_per_batch, size1*size2)
                    # in_boxes_and_center: ä¸€ä¸ªmaskï¼Œçºµè½´è¡¨ç¤ºæ¯ä¸ªGTåŒ¹é…åˆ°çš„æ­£æ ·æœ¬
                    # in_boxes_and_center.sum(1) # è¡¨ç¤ºåŒä¸€è¡Œå…¨éƒ¨ç›¸åŠ ï¼Œç»“æœæ˜¯è¡Œçš„ä¸ªæ•°ï¼Œæ¯ä¸ªä½ç½®è¡¨ç¤ºGTæœ‰å¤šå°‘ä¸ªåŒ¹é…åˆ°çš„Anchor
                    anchor_mask, in_boxes_and_center = self.get_anchor_info(batch_pi, batch_targets, num_gt_per_batch,
                                                                            layer_index=layer_id)
                    get_mask = anchor_mask.unsqueeze(0).repeat(num_gt_per_batch,1)

                    matched_mask = get_mask.sum(0) > 0# è¡¨ç¤ºè¢«åŒ¹é…åˆ°çš„anchorçš„maskçŸ©é˜µ
                    matched_anchor=(get_mask.sum(0) > 0).sum().item()  # è¡¨ç¤ºè¢«åŒ¹é…åˆ°çš„anchorçš„ä¸ªæ•°
                    matched_cls_index=get_mask.to(torch.int64)[:,matched_mask].argmax(0) # è¡¨ç¤ºè¢«åŒ¹é…ä¸Šçš„ç±»åˆ«id

                    # è·å–çœŸå®å€¼çš„ä¿¡æ¯
                    gt_bboxes = batch_targets[:num_gt_per_batch, 2:6]
                    gt_angles = batch_targets[:num_gt_per_batch, 6]
                    gt_classes = batch_targets[:num_gt_per_batch, 1]  #

                    # å¤„ç†åŒ¹é…åˆ°çš„anchorçš„å„ç§å±æ€§
                    cls_target = F.one_hot(gt_classes[matched_cls_index].to(torch.int64), self.nc)   # (num_select_final, self.nc)
                    obj_target = anchor_mask.unsqueeze(-1)  # ï¼ˆtotal_num_anchor, 1ï¼‰
                    # obj_target = mask_in_boxes.unsqueeze(-1)  # ï¼ˆn_anchor_select_final, 1ï¼‰
                    reg_target = gt_bboxes[matched_cls_index]  # (n_anchor_select_final, 4)
                    angle_target = gt_angles[matched_cls_index]  # add  ï¼ˆn_anchor_select_finalï¼‰

                    # ç›´æ¥ç”¨åˆæ­¥ç­›é€‰å¾—åˆ°çš„æ­£æ ·æœ¬è¿›è¡Œå›å½’å’Œåˆ†ç±»
                else:
                    cls_target = pi.new_zeros((0, self.nc))
                    reg_target = pi.new_zeros((0, 4))
                    angle_target = pi.new_zeros(0)
                    obj_target = pi.new_zeros((pi.shape[1], 1))
                    anchor_mask = pi.new_zeros(pi.shape[1]).bool()
                cls_targets.append(cls_target)
                reg_targets.append(reg_target)
                angle_targets.append(angle_target)  # add
                obj_targets.append(obj_target)
                anchor_masks.append(anchor_mask)

        return cls_targets, reg_targets, angle_targets, obj_targets, anchor_masks

    '''
    åŠŸèƒ½ï¼šåˆæ­¥ç­›é€‰æ­£æ ·æœ¬çš„anchorï¼Œä¸ºç²¾ç»†åŒ–ç­›é€‰åšå‡†å¤‡
    '''
    def get_anchor_info(self, pi, targets, num_gt_per_batch, layer_index):
        '''
        @param pi: ä¼ å…¥çš„æ˜¯batchä¸­æŸä¸€ä¸ªçš„ç‰¹å¾å›¾ï¼Œsize = (1ç§scaleæ¡† * size1 * size2, [x,y,w,h,theta,obj,classes])
            eg: å°†æ£€æµ‹å¤´çš„æ¯ä¸€å±‚è¾“å‡ºçš„ç‰¹å¾å›¾wï¼Œhè¿›è¡Œåˆå¹¶
        @param targets: å½“å‰batchä¸­æŸä¸€ä¸ªimageçš„targetsï¼Œshape=(num_gt_per_batch, [class,x,y,w,h,theta])
        '''
        # exp_strides = []  # ä¿å­˜é‡‡æ ·ç‡
        strides = [6, 16, 32]  # ä¸‰å±‚layerçš„é‡‡æ ·ç‡
        num_anchor, num_gt_per_batch = self.na, num_gt_per_batch  # é¢„æµ‹æ¡†çš„ç§ç±», å½“å‰imageä¸­æ ‡ç­¾å€¼çš„æ•°é‡

        # è¿”å›æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„æ­£æ ·æœ¬anchorï¼Œå®ƒæ˜¯ä¸€ä¸ªlistï¼Œsize=3
        boxes_or_center = []
        boxes_and_center = []

        # åˆå§‹åŒ–ç½‘æ ¼ç©ºé—´çš„ç¼©æ”¾å¢ç›Š
        gain = torch.ones(7, device=targets.device)
        xx = [1, int(np.sqrt(pi.shape[0])), int(np.sqrt(pi.shape[0])), 1]  # (w,h,22)
        gain[2:6] = torch.tensor(xx)[[2, 1, 2, 1]]  # ç‰¹å¾å›¾çš„w,h,w,h

        # targets: size=(num_anchor, num_gt,[image,class_id,x,y,w,h,theta])
        t = targets * gain  # å°†æ ‡ç­¾å€¼ç¼©æ”¾åˆ°ç‰¹å¾å›¾ä¸Š

        # æ‰€æœ‰çš„anchoræ•°é‡
        total_num_anchors = pi.shape[0]

        # è·å–gridçš„x,yåæ ‡
        if RANK != -1:  # DDP
            x_shifts = self.model.module.model[-1].grid[layer_index][:, :, 0]
            y_shifts = self.model.module.model[-1].grid[layer_index][:, :, 1]
        else:
            x_shifts = self.model.model[-1].grid[layer_index][:, :, 0]  # shape = (1, size1*size2)
            y_shifts = self.model.model[-1].grid[layer_index][:, :, 1]

        # exp_stride: ä¿å­˜æ¯ä¸€å±‚çš„é‡‡æ ·é—´éš”ï¼Œsize=(1, grid.shape[1])
        exp_strides = torch.zeros(1, pi.shape[0]).fill_(strides[layer_index]).type_as(pi[0])

        # è·å–æ¯ä¸ªç‰¹å¾å›¾çš„x,yæ ¼ç‚¹åæ ‡
        # x_shifts_per_img = x_shifts * exp_strides[layer_index]
        # y_shifts_per_img = y_shifts * exp_strides[layer_index]
        x_shifts_per_img = x_shifts[0] * exp_strides
        y_shifts_per_img = y_shifts[0] * exp_strides

        # è·å–æ¯ä¸ªæ ¼ç‚¹çš„ä¸­å¿ƒåæ ‡,å·¦ä¸Šè§’ä¸ºåŸç‚¹
        # x_c_per_img.shape = [num_gt_per_batch, total_num_anchors]
        x_c_per_img = ((x_shifts_per_img + 0.5 * exp_strides).repeat(num_gt_per_batch, 1))
        y_c_per_img = ((y_shifts_per_img + 0.5 * exp_strides).repeat(num_gt_per_batch, 1))

        # TODOï¼šåˆæ­¥ç­›é€‰
        # è®¡ç®—æ ‡ç­¾çš„å·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡ï¼Œå³ï¼ˆ[left,top], [right,bottom])
        # gt_xxxä¸x_c_per_imgç»´åº¦åº”è¯¥ç›¸åŒ
        # gt_l = ( (t[: , :, 2] - 0.5 * t[:, :, 4]).squeeze(1).repeat(1,total_num_anchors))
        # gt_t = ( (t[: , :, 3] - 0.5 * t[:, :, 5]).squeeze(1).repeat(1,total_num_anchors))
        # gt_r = ( (t[: , :, 2] + 0.5 * t[:, :, 4]).squeeze(1).repeat(1,total_num_anchors))
        # gt_b = ( (t[: , :, 3] + 0.5 * t[:, :, 5]).squeeze(1).repeat(1,total_num_anchors))
        gt_l = ((t[:, 2] - 0.5 * t[:, 4]).unsqueeze(1).repeat(1, total_num_anchors))  # shape=(num_gt_per_img, total_anchors)
        gt_t = ((t[:, 3] - 0.5 * t[:, 5]).unsqueeze(1).repeat(1, total_num_anchors))
        gt_r = ((t[:, 2] + 0.5 * t[:, 4]).unsqueeze(1).repeat(1, total_num_anchors))
        gt_b = ((t[:, 3] + 0.5 * t[:, 5]).unsqueeze(1).repeat(1, total_num_anchors))

        # TODO ï¼šanchor freeçš„æ€è·¯æ˜¯æ¯ä¸ªæ ¼ç‚¹éƒ½ä½œä¸ºä¸€ä¸ªé¢„æµ‹çš„anchorï¼Œå› æ­¤anchoræ•°é‡å°±æ˜¯å½“å‰çš„ç‰¹å¾å›¾å¤§å°;
        # è®¡ç®—å‡ºæ¯ä¸ªanchorçš„å·¦ä¸Šè§’å’Œå³ä¸Šè§’åæ ‡ï¼ˆå·¦ä¸Šè§’ä¸ºåŸç‚¹ï¼‰ï¼Œç„¶åä¸çœŸå®çš„æ ‡ç­¾å€¼è¿›è¡Œåˆ¤æ–­â€œå½“å‰anchoræ˜¯å¦å¤„äºGTçš„å†…éƒ¨â€ï¼šå¦‚æœæ˜¯åˆ™ä¸ºæ­£æ ·æœ¬
        bbox_l = x_c_per_img - gt_l
        bbox_r = gt_r - x_c_per_img
        bbox_t = y_c_per_img - gt_t
        bbox_b = gt_b - y_c_per_img
        bboxes = torch.stack([bbox_l, bbox_t, bbox_r, bbox_b], 2)  # size = (num_gt, feature_size1*feature_size2,4)

        # ç„¶åå°†æ‰€æœ‰è½åœ¨GTä¸­çš„anchoræŒ‘é€‰å‡ºæ¥
        in_boxes = bboxes.min(dim=-1).values > 0.0  # å¿…é¡»å…¨éƒ¨å¤§äº0æ‰æ˜¯éœ€è¦çš„anchor
        in_boxes_all = in_boxes.sum(dim=0) > 0  # ä¸­å¿ƒç‚¹ä½äºæ ‡æ³¨æ¡†å†…çš„é”šæ¡†ä¸ºTrue,ç›¸å½“äºä¸€ä¸ªmask

        # TODO å†æ¬¡ç­›é€‰ï¼šç»˜åˆ¶ä¸€ä¸ªè¾¹é•¿ä¸º5çš„æ­£æ–¹å½¢ã€‚å·¦ä¸Šè§’ç‚¹ä¸ºï¼ˆgt_lï¼Œgt_tï¼‰ï¼Œå³ä¸‹è§’ç‚¹ä¸ºï¼ˆgt_rï¼Œgt_bï¼‰ã€‚gtä»¥æ­£æ–¹å½¢èŒƒå›´å½¢å¼å»æŒ‘é€‰é”šæ¡†
        radius = 2  # åŠå¾„
        # gt_l = (targets[:, 2].unsqueeze(1).repeat(1, total_num_anchors)) - radius * exp_strides[i]# x - radius*stride
        # gt_r = (targets[:, 2].unsqueeze(1).repeat(1, total_num_anchors)) + radius * exp_strides[i]
        # gt_t = (targets[:, 3].unsqueeze(1).repeat(1, total_num_anchors)) - radius * exp_strides[i]
        # gt_b = (targets[:, 3].unsqueeze(1).repeat(1, total_num_anchors)) + radius * exp_strides[i]
        gt_l = (t[:, 2].unsqueeze(1).repeat(1, total_num_anchors)) - radius * exp_strides  # x - radius*stride
        gt_t = (t[:, 3].unsqueeze(1).repeat(1, total_num_anchors)) - radius * exp_strides
        gt_r = (t[:, 2].unsqueeze(1).repeat(1, total_num_anchors)) + radius * exp_strides
        gt_b = (t[:, 3].unsqueeze(1).repeat(1, total_num_anchors)) + radius * exp_strides
        # gt_b = (t[:, :, 3].squeeze(0).unsqueeze(1).repeat(1, total_num_anchors)) + radius * exp_strides[layer_index]

        c_l = x_c_per_img - gt_l
        c_r = gt_r - x_c_per_img
        c_t = y_c_per_img - gt_t
        c_b = gt_b - y_c_per_img
        center = torch.stack([c_l, c_t, c_r, c_b], 2)
        in_centers = center.min(dim=-1).values > 0.0
        in_centers_all = in_centers.sum(dim=0) > 0

        # æŸä¸€è¾¹åœ¨gté‡Œé¢
        # boxes_or_center.append(in_boxes_all | in_centers_all)
        boxes_or_center = in_boxes_all | in_centers_all  # é listç‰ˆæœ¬

        # ä¸¤è€…éƒ½åœ¨gté‡Œé¢
        # boxes_and_center.append(in_boxes[:, boxes_or_center[i]] & in_centers[:, boxes_or_center[i]])
        boxes_and_center = in_boxes[:, boxes_or_center] & in_centers[:, boxes_or_center]  # é listç‰ˆæœ¬

        return boxes_or_center, boxes_and_center

    # ä½¿ç”¨GIou lossæ¥è®¡ç®—æ—‹è½¬æ¡†çš„LOSS
    def giou_loss(self, p_box, t_box, x1y1x2y2=False, GIoU=True,eps=1e-7):
        # p_box1 [[x,y,w,h,angle], n]
        assert p_box.shape[0] == t_box.shape[0]
        N = p_box.shape[0]
        M = t_box.shape[0]
        overlaps = np.zeros((N,M),dtype=np.float32)
        # p_box = p_box.T # [n,5]->[5,n]
        # t_box = t_box.T # [m,5]->[5,m]

        # Get the coordinates of bounding boxes
        if x1y1x2y2:  # x1, y1, x2, y2 = p_box
            p_x1, p_y1, p_x2, p_y2 = p_box[0], p_box[1], p_box[2], p_box[3]
            t_x1, t_y1, t_x2, t_y2 = t_box[0], t_box[1], t_box[2], t_box[3]
        else:
            # TODO: x,y,w,h,angleè½¬åŒ–ä¸ºx1,y1,x2,y2,å·¦ä¸Šè§’å’Œå³ä¸‹è§’
            p_x1, p_x2 = p_box[0] - p_box[2] / 2, p_box[0] + p_box[2] / 2
            p_y1, p_y2 = p_box[1] - p_box[3] / 2, p_box[1] + p_box[3] / 2
            t_x1, t_x2 = t_box[0] - t_box[2] / 2, t_box[0] + t_box[2] / 2
            t_y1, t_y2 = t_box[1] - t_box[3] / 2, t_box[1] + t_box[3] / 2

        iou = None
        union = None

        for i in range(N):
            p_area = p_box[i][2] * p_box[i][3]
            for j in range(M):
                t_area = t_box[j][2] * t_box[j][3]
                union = p_area + t_area + eps

                box1 = ((p_box[i][0].item(),p_box[i][1].item()), (p_box[i][2].item(),p_box[i][3].item()), (p_box[i][4].item()))
                box2 = ((t_box[j][0].item(),t_box[j][1].item()), (t_box[j][2].item(),t_box[j][3].item()), (t_box[j][4].item()))

                # è®¡ç®—ä¸¤ä¸ªrectangleä¹‹é—´æ˜¯å¦æœ‰äº¤é›†
                # å¦‚æœæœ‰äº¤é›†ï¼Œé‚£ä¹ˆä¼šè¿”å›äº¤é›†çš„æ‰€æœ‰ç›¸äº¤çš„é¡¶ç‚¹å³ contours
                flag, contours = cv2.rotatedRectangleIntersection(box1, box2)

                if flag ==1:
                    inter = np.round(np.abs(cv2.contourArea(contours)))
                    overlaps[i,j] = inter / (union - inter) # è®¡ç®—äº¤å¹¶æ¯”

                if flag ==2:
                    inter = np.minimum(union-t_area, t_area)
                    overlaps[i,j] = inter / (union - inter) # è®¡ç®—äº¤å¹¶æ¯”

        # cv2.boxPoints(box1) # xywhaå½¢å¼çš„boxè¿”å›å››ä¸ªé¡¶ç‚¹


        # è®¡ç®—ä¸¤ä¸ªæ—‹è½¬æ¡†çš„IoU
        # inter = (torch.min(p_x2, t_x2) - torch.max(p_x1, t_x1)).clamp(0) * \
        #         (torch.min(p_y2, t_y2) - torch.max(p_y1, t_y1)).clamp(0)
        #
        # # Union Area
        # w1, h1 = p_x2 - p_x1, p_y2 - p_y1 + eps
        # w2, h2 = t_x2 - t_x1, t_y2 - t_y1 + eps
        # union = w1 * h1 + w2 * h2 - inter + eps


        if GIoU :
            cw = torch.max(p_x2, t_x2) - torch.min(p_x1, t_x1)  # convex (smallest enclosing box) width
            ch = torch.max(p_y2, t_y2) - torch.min(p_y1, t_y1)  # convex height
             # GIoU https://arxiv.org/pdf/1902.09630.pdf
            c_area = cw * ch + eps  # convex area
            return iou - (c_area - union) / c_area  # GIoU
        else:
            return iou  # IoU

class ComputeLoss_AnchorFree_FCOS:
    def __init__(self, model, autobalance=False):
        self.sort_obj_iou = False
        device = next(model.parameters()).device  # get model device
        h = model.hyp  # hyperparameters
        self.class_index = 5 + model.nc
        self.model = model  # å¤åˆ¶modelï¼Œæ–¹ä¾¿åé¢ç´¢å¼•ï¼Œadd

        # Define criteria
        BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['cls_pw']], device=device))
        BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h['obj_pw']], device=device))
        BCEangle = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([h['angle_pw']])).to(device)

        # Class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3
        self.cp, self.cn = smooth_BCE(eps=h.get('label_smoothing', 0.0))  # positive, negative BCE targets

        # Focal loss
        g = h['fl_gamma']  # focal loss gamma
        if g > 0:
            BCEcls, BCEobj = FocalLoss(BCEcls, g), FocalLoss(BCEobj, g)
            BCEangle = FocalLoss(BCEangle, g)

        # è·å–æ¯ä¸€å±‚çš„output
        det = model.module.model[-1] if is_parallel(model) else model.model[-1]  # Detect() module
        self.balance = {3: [4.0, 1.0, 0.4]}.get(det.nl, [4.0, 1.0, 0.25, 0.06, .02])  # P3-P7
        self.ssi = list(det.stride).index(16) if autobalance else 0  # stride 16 index
        self.BCEcls, self.BCEobj, self.gr, self.hyp, self.autobalance = BCEcls, BCEobj, 1.0, h, autobalance
        self.BCEangle = BCEangle
        self.iou_loss = KLDloss()  # add

        # è®¾ç½®å±æ€§
        for k in 'na', 'nc', 'nl', 'anchors':
            setattr(self, k, getattr(det, k))

    def __call__(self, p, targets, imgs=None, img_path=None):  # predictions, targets, model, å¢åŠ äº†ä¸¤ä¸ªå¯è§†åŒ–å‚æ•°imgs, img_path
        '''
            @param p: list: [small_forward, medium_forward, large_forward]
                eg:small_forward.size=( batch_size, 1ç§scaleæ¡†, size1, size2, [class,x,y,w,h,theta])
            @param targets: shape=(num_gt, [batch_size, class_id, x,y,w,h,theta])
        '''
        device = targets.device

    def build_targets(self,p,targets):
        pass
        '''
            
        '''

if __name__=='__main__':
    logging.basicConfig(format='%(asctime)s - %(levelname)s: %(message)s ', level=logging.INFO)

    """
            yolov5l: Model Summary: 499 layers, 48026065 parameters, 48026065 gradients, 118.7 GFLOPs
            yolov5m: Model Summary: 391 layers, 22103025 parameters, 22103025 gradients, 53.8 GFLOPs;
            yolov5s: Model Summary: 283 layers, 7762065 parameters, 7762065 gradients, 18.6 GFLOPs;
            yolov5x: Model Summary: 607 layers, 88987185 parameters, 88987185 gradients, 222.9 GFLOPs
            yolov5m-asff: 10948910
    """
    parser = argparse.ArgumentParser()
    parser.add_argument('--cfg', type=str, default='../models/yolov5m.yaml', help='model.yaml')
    # parser.add_argument('--cfg', type=str, default='yolov5m-anchor-free-decoupled.yaml', help='model.yaml')
    parser.add_argument('--hyp', type=str,
                        default='..//data/hyps/hyp.scratch.yaml',
                        # default=os.path.dirname(os.path.abspath(__file__)) + '/data/hyps/hyp.finetune_anchor_free.yaml',
                        # default=os.path.dirname(os.path.abspath(__file__)) + '/data/hyps/hyp.scratch_anchor_free.yaml',
                        help='hyperparameters path')
    parser.add_argument('--device', default='2', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--profile', action='store_true', help='profile model speed')
    opt = parser.parse_args()
    opt.cfg = check_yaml(opt.cfg)  # check YAML
    with open(opt.hyp) as f:
        hyp = yaml.safe_load(f)  # load hyps dict
    device = select_device(opt.device)
    logging.info(opt.cfg)

    # Create model
    model = Model(opt.cfg, ch=3, nc=16, anchors=hyp.get('anchors')).to(device)
    logging.info("loaded model done!")

    loss = ComputeLoss_AnchorFree_Decoupled_CenterPoint(model,hyp = hyp)



